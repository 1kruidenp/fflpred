{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffe726ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from merge_years.import_data import get_full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c90319e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = get_full_data('../raw_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b30cbf8",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1594e3",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Roll_match_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2722e6aa",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def roll_match_features(df, roll=10, method='mean'):\n",
    "    '''\n",
    "    Returns the lagged dataframe with a chosen method and lagging window\n",
    "    Adds a 'real_total_points' column\n",
    "    '''\n",
    "    # splitting into game features and known features\n",
    "    known_features = ['name', 'opponent_team','kickoff_time','was_home',\n",
    "                      'opponent_level','team_level','dreamteam_yearly_average','GW',\n",
    "                      'team_id','season','kickoff_date','position']\n",
    "\n",
    "    game_features = ['name','assists', 'bonus', 'bps', 'clean_sheets','creativity','goals_conceded',\n",
    "                     'threat','goals_scored', 'ict_index','influence','kickoff_time', 'minutes',\n",
    "                     'own_goals','penalties_missed', 'penalties_saved','red_cards', 'saves',\n",
    "                     'transfers_balance','value','yellow_cards','team_a_score','team_h_score',\n",
    "                     'total_points']\n",
    "    \n",
    "    df_pre_match = df[known_features]\n",
    "    df_match = df[game_features]\n",
    "    \n",
    "    # roll with a given method\n",
    "    rolled_df = df_match.groupby('name')\n",
    "    if method == 'mean':\n",
    "        rolled_df = rolled_df.rolling(roll,closed='left').mean()\n",
    "    elif method == 'max':\n",
    "        rolled_df = rolled_df.rolling(roll,closed='left').max()\n",
    "    elif method == 'min':\n",
    "        rolled_df = rolled_df.rolling(roll,closed='left').min()\n",
    "    else: #do a mean() meathod\n",
    "        rolled_df = rolled_df.rolling(roll,closed='left').mean()\n",
    "\n",
    "    rolled_df.reset_index(inplace=True)\n",
    "    \n",
    "    # Add back the un-lagged, real total_points\n",
    "    rolled_df['real_total_points'] = np.array(df_match['total_points'])\n",
    "    \n",
    "    # Rename the rolled columns to how they were rolled\n",
    "    game_features.remove('name')\n",
    "    game_features_rolled=[]\n",
    "    for feat in game_features:\n",
    "        game_features_rolled.append('r_' + feat)\n",
    "    feat_new_names_dict = dict(zip(game_features, game_features_rolled))\n",
    "    rolled_df.rename(feat_new_names_dict,axis=1, inplace=True)\n",
    "    \n",
    "    # Join the features available pre-match\n",
    "    data = rolled_df.join(df_pre_match.reset_index()[['was_home','GW','position','season']])\n",
    "    \n",
    "    # Delete the NaN values fromn the rolled 'points_pred' columns\n",
    "    data = data[~data.r_total_points.isnull()]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9fef8c",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35634a37",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c5b1d93",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def pre_processing(data):\n",
    "    # Adding the missing r_team_scores:\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "    data[\"r_team_h_score\"] = imp.fit_transform(data[[\"r_team_h_score\"]])\n",
    "    data[\"r_team_a_score\"] = imp.fit_transform(data[[\"r_team_a_score\"]])\n",
    "    \n",
    "    # Adding missing positions to 1 defender (15 rows)\n",
    "    imp_string = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=\"DEF\")\n",
    "    data[\"position\"] = imp_string.fit_transform(data[[\"position\"]])\n",
    "    \n",
    "    print(f'number of positions = {len(data.position.unique())}')\n",
    "    if len(data.position.unique()) == 4:\n",
    "        # OHE positions if ['DEF','FWD','GK','MID']\n",
    "        enc=OneHotEncoder()\n",
    "        enc.fit(data[['position']])\n",
    "        positions=enc.transform(data[['position']]).toarray()\n",
    "        data[\"DEF\"], data[\"FWD\"], data['GK'], data['MID'] = positions.T\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    # Was_home\n",
    "    data['was_home'] = data.was_home.map(int)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea520d9",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "376cfdda",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def split(data, roll=10,drop=[\"name\",\"season\",\"position\",\"GW\"]):\n",
    "    # Train & Test\n",
    "    test_data = data[(data.season > 20) & (data.GW >= 29-roll)]\n",
    "    train_data = data[~((data.season > 20) & (data.GW >= 29-roll))]\n",
    "    \n",
    "    # X & y train\n",
    "    X_train = train_data.drop('real_total_points', axis = 1)\n",
    "    y_train = train_data.real_total_points\n",
    "    \n",
    "    # X & y test\n",
    "    X_test = test_data.drop('real_total_points', axis = 1)\n",
    "    y_test = test_data.real_total_points\n",
    "    \n",
    "    # drop features\n",
    "    X_train.drop(drop,axis=1,inplace=True)\n",
    "    X_test.drop(drop,axis=1,inplace=True)\n",
    "    \n",
    "    return (X_train,X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a27ab71",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc1f04f5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc665fec",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def scale(X_train, X_test):\n",
    "    print(X_train.columns)\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return (X_train_scaled, X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50a4d5e",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### All in One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c63d223",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def model_ready(df, drop=[\"name\",\"level_1\",\"season\",\"position\",\"GW\"], roll=3):\n",
    "    '''\n",
    "    Can take \"full_data\" or \"fwd_data\" as input\n",
    "    Returns X_train_scaled, X_test_scaled, y_train y_test\n",
    "    '''\n",
    "    # Roll the game-related features, keep the known features\n",
    "    unclean_data = roll_match_features(df, roll=roll)\n",
    "    \n",
    "    # preprocess\n",
    "    data = pre_processing(unclean_data)\n",
    "    \n",
    "    #split\n",
    "    X_train, X_test, y_train, y_test = split(data, roll=roll, drop=drop)\n",
    "    \n",
    "    #scale\n",
    "    X_train_scaled, X_test_scaled = scale(X_train,X_test)\n",
    "    \n",
    "    return(X_train_scaled, X_test_scaled, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74096b4",
   "metadata": {},
   "source": [
    "## only playing players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3392e894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114992, 40)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a26cfcb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((52443, 40),\n",
       " Index(['name', 'assists', 'bonus', 'bps', 'clean_sheets', 'creativity',\n",
       "        'element', 'fixture', 'goals_conceded', 'goals_scored', 'ict_index',\n",
       "        'influence', 'kickoff_time', 'minutes', 'opponent_team', 'own_goals',\n",
       "        'penalties_missed', 'penalties_saved', 'red_cards', 'saves', 'selected',\n",
       "        'team_a_score', 'team_h_score', 'threat', 'total_points',\n",
       "        'transfers_balance', 'transfers_in', 'transfers_out', 'value',\n",
       "        'was_home', 'yellow_cards', 'GW', 'season', 'position',\n",
       "        'dreamteam_yearly_average', 'team_id', 'team_name', 'opponent_level',\n",
       "        'team_level', 'kickoff_date'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players_data = full_data[full_data['minutes'] > 0]\n",
    "players_data.shape, players_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "876979e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of positions = 4\n",
      "Index(['r_assists', 'r_bonus', 'r_bps', 'r_clean_sheets', 'r_creativity',\n",
      "       'r_goals_conceded', 'r_threat', 'r_goals_scored', 'r_ict_index',\n",
      "       'r_influence', 'r_minutes', 'r_own_goals', 'r_penalties_missed',\n",
      "       'r_penalties_saved', 'r_red_cards', 'r_saves', 'r_transfers_balance',\n",
      "       'r_value', 'r_yellow_cards', 'r_team_a_score', 'r_team_h_score',\n",
      "       'r_total_points', 'was_home', 'DEF', 'FWD', 'GK', 'MID'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled,X_test_scaled,useless_y_train,useless_y_test  = model_ready(players_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689a9065",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40e2a37",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "960a62a3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2cdd5a48",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "reg_l1 = regularizers.L1(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75798f93",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def init_model(dim, learn = 0.00003, dropout = False):\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    model.add(layers.Dense(35, input_dim=dim, activation='relu'))\n",
    "    if dropout:\n",
    "        model.add(layers.Dropout(rate = 0.01))\n",
    "    pass\n",
    "\n",
    "    model.add(layers.Dense(17, activation='relu', kernel_regularizer=reg_l1))\n",
    "    if dropout:\n",
    "        model.add(layers.Dropout(rate = 0.01))\n",
    "    pass\n",
    "\n",
    "    model.add(layers.Dense(8, activation='relu'))\n",
    "    if dropout:\n",
    "        model.add(layers.Dropout(rate = 0.01))\n",
    "    \n",
    "    # output layer for regression task\n",
    "    model.add(layers.Dense(1, activation='linear'))\n",
    "    \n",
    "    model.compile(loss='mse', \n",
    "                  optimizer=Adam(learning_rate=learn),\n",
    "                  metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed41125",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### SCORE = 2.1062543392181396 - first : rows with minutes > 1 only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e1a2affb",
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of positions = 4\n",
      "Index(['r_assists', 'r_bonus', 'r_bps', 'r_clean_sheets', 'r_creativity',\n",
      "       'r_goals_conceded', 'r_threat', 'r_goals_scored', 'r_ict_index',\n",
      "       'r_influence', 'r_minutes', 'r_own_goals', 'r_penalties_missed',\n",
      "       'r_penalties_saved', 'r_red_cards', 'r_saves', 'r_transfers_balance',\n",
      "       'r_value', 'r_yellow_cards', 'r_team_a_score', 'r_team_h_score',\n",
      "       'r_total_points', 'was_home', 'DEF', 'FWD', 'GK', 'MID'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(47078, 27)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players_data = full_data[full_data['minutes'] > 0]\n",
    "\n",
    "drop = [\"name\",\"level_1\",\"season\",\"position\",\"GW\"]\n",
    "roll = 2\n",
    "\n",
    "X_train_scaled, X_test_scaled, y_train, y_test = model_ready(players_data, drop, roll)\n",
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "28d0ceee",
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1030/1030 [==============================] - 2s 2ms/step - loss: 12.7279 - mae: 2.1548 - val_loss: 12.0781 - val_mae: 2.0949\n",
      "Epoch 2/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 10.3880 - mae: 1.9928 - val_loss: 10.8650 - val_mae: 2.1299\n",
      "Epoch 3/300\n",
      "1030/1030 [==============================] - 2s 2ms/step - loss: 9.7171 - mae: 2.0499 - val_loss: 10.5089 - val_mae: 2.1733\n",
      "Epoch 4/300\n",
      "1030/1030 [==============================] - 2s 2ms/step - loss: 9.4721 - mae: 2.0811 - val_loss: 10.3179 - val_mae: 2.1778\n",
      "Epoch 5/300\n",
      "1030/1030 [==============================] - 2s 2ms/step - loss: 9.3223 - mae: 2.0844 - val_loss: 10.1848 - val_mae: 2.1793\n",
      "Epoch 6/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 9.2123 - mae: 2.0858 - val_loss: 10.0838 - val_mae: 2.1796\n",
      "Epoch 7/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 9.1272 - mae: 2.0836 - val_loss: 10.0042 - val_mae: 2.1813\n",
      "Epoch 8/300\n",
      "1030/1030 [==============================] - 2s 1ms/step - loss: 9.0598 - mae: 2.0852 - val_loss: 9.9402 - val_mae: 2.1758\n",
      "Epoch 9/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 9.0057 - mae: 2.0828 - val_loss: 9.8908 - val_mae: 2.1736\n",
      "Epoch 10/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.9606 - mae: 2.0780 - val_loss: 9.8471 - val_mae: 2.1781\n",
      "Epoch 11/300\n",
      "1030/1030 [==============================] - 2s 1ms/step - loss: 8.9223 - mae: 2.0789 - val_loss: 9.8105 - val_mae: 2.1774\n",
      "Epoch 12/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.8897 - mae: 2.0795 - val_loss: 9.7802 - val_mae: 2.1711\n",
      "Epoch 13/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.8616 - mae: 2.0777 - val_loss: 9.7539 - val_mae: 2.1705\n",
      "Epoch 14/300\n",
      "1030/1030 [==============================] - 2s 2ms/step - loss: 8.8371 - mae: 2.0760 - val_loss: 9.7299 - val_mae: 2.1695\n",
      "Epoch 15/300\n",
      "1030/1030 [==============================] - 2s 2ms/step - loss: 8.8146 - mae: 2.0715 - val_loss: 9.7096 - val_mae: 2.1762\n",
      "Epoch 16/300\n",
      "1030/1030 [==============================] - 2s 2ms/step - loss: 8.7945 - mae: 2.0760 - val_loss: 9.6918 - val_mae: 2.1734\n",
      "Epoch 17/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.7756 - mae: 2.0705 - val_loss: 9.6735 - val_mae: 2.1794\n",
      "Epoch 18/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.7587 - mae: 2.0763 - val_loss: 9.6565 - val_mae: 2.1714\n",
      "Epoch 19/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.7419 - mae: 2.0699 - val_loss: 9.6410 - val_mae: 2.1748\n",
      "Epoch 20/300\n",
      "1030/1030 [==============================] - 2s 2ms/step - loss: 8.7273 - mae: 2.0735 - val_loss: 9.6274 - val_mae: 2.1737\n",
      "Epoch 21/300\n",
      "1030/1030 [==============================] - 2s 1ms/step - loss: 8.7122 - mae: 2.0725 - val_loss: 9.6135 - val_mae: 2.1700\n",
      "Epoch 22/300\n",
      "1030/1030 [==============================] - 2s 1ms/step - loss: 8.6983 - mae: 2.0684 - val_loss: 9.6023 - val_mae: 2.1741\n",
      "Epoch 23/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.6854 - mae: 2.0709 - val_loss: 9.5905 - val_mae: 2.1723\n",
      "Epoch 24/300\n",
      "1030/1030 [==============================] - 2s 2ms/step - loss: 8.6730 - mae: 2.0703 - val_loss: 9.5781 - val_mae: 2.1694\n",
      "Epoch 25/300\n",
      "1030/1030 [==============================] - 2s 2ms/step - loss: 8.6613 - mae: 2.0683 - val_loss: 9.5672 - val_mae: 2.1699\n",
      "Epoch 26/300\n",
      "1030/1030 [==============================] - 2s 2ms/step - loss: 8.6502 - mae: 2.0681 - val_loss: 9.5568 - val_mae: 2.1714\n",
      "Epoch 27/300\n",
      "1030/1030 [==============================] - 2s 2ms/step - loss: 8.6392 - mae: 2.0679 - val_loss: 9.5475 - val_mae: 2.1736\n",
      "Epoch 28/300\n",
      "1030/1030 [==============================] - 2s 2ms/step - loss: 8.6285 - mae: 2.0703 - val_loss: 9.5396 - val_mae: 2.1706\n",
      "Epoch 29/300\n",
      "1030/1030 [==============================] - 2s 2ms/step - loss: 8.6183 - mae: 2.0661 - val_loss: 9.5293 - val_mae: 2.1730\n",
      "Epoch 30/300\n",
      "1030/1030 [==============================] - 2s 2ms/step - loss: 8.6088 - mae: 2.0692 - val_loss: 9.5198 - val_mae: 2.1709\n",
      "Epoch 31/300\n",
      "1030/1030 [==============================] - 2s 1ms/step - loss: 8.5989 - mae: 2.0687 - val_loss: 9.5103 - val_mae: 2.1678\n",
      "Epoch 32/300\n",
      "1030/1030 [==============================] - 2s 2ms/step - loss: 8.5885 - mae: 2.0636 - val_loss: 9.5054 - val_mae: 2.1781\n",
      "Epoch 33/300\n",
      "1030/1030 [==============================] - 2s 2ms/step - loss: 8.5807 - mae: 2.0690 - val_loss: 9.4961 - val_mae: 2.1720\n",
      "Epoch 34/300\n",
      "1030/1030 [==============================] - 2s 2ms/step - loss: 8.5712 - mae: 2.0668 - val_loss: 9.4871 - val_mae: 2.1710\n",
      "Epoch 35/300\n",
      "1030/1030 [==============================] - 2s 2ms/step - loss: 8.5628 - mae: 2.0676 - val_loss: 9.4788 - val_mae: 2.1663\n",
      "Epoch 36/300\n",
      "1030/1030 [==============================] - 2s 2ms/step - loss: 8.5547 - mae: 2.0644 - val_loss: 9.4731 - val_mae: 2.1722A: 0s - loss: 8.4877 - mae: 2. - ETA: 0s - loss: 8.6397 -\n",
      "Epoch 37/300\n",
      "1030/1030 [==============================] - 2s 2ms/step - loss: 8.5465 - mae: 2.0663 - val_loss: 9.4651 - val_mae: 2.1712\n",
      "Epoch 38/300\n",
      "1030/1030 [==============================] - 2s 2ms/step - loss: 8.5385 - mae: 2.0686 - val_loss: 9.4587 - val_mae: 2.1663\n",
      "Epoch 39/300\n",
      "1030/1030 [==============================] - 2s 2ms/step - loss: 8.5310 - mae: 2.0642 - val_loss: 9.4516 - val_mae: 2.1694\n",
      "Epoch 40/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.5233 - mae: 2.0661 - val_loss: 9.4449 - val_mae: 2.1700\n",
      "Epoch 41/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.5156 - mae: 2.0642 - val_loss: 9.4374 - val_mae: 2.1732\n",
      "Epoch 42/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.5079 - mae: 2.0641 - val_loss: 9.4323 - val_mae: 2.1769\n",
      "Epoch 43/300\n",
      "1030/1030 [==============================] - 2s 1ms/step - loss: 8.5011 - mae: 2.0678 - val_loss: 9.4235 - val_mae: 2.1687\n",
      "Epoch 44/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.4936 - mae: 2.0662 - val_loss: 9.4179 - val_mae: 2.1668\n",
      "Epoch 45/300\n",
      "1030/1030 [==============================] - 2s 1ms/step - loss: 8.4866 - mae: 2.0640 - val_loss: 9.4128 - val_mae: 2.1705\n",
      "Epoch 46/300\n",
      "1030/1030 [==============================] - 2s 2ms/step - loss: 8.4798 - mae: 2.0649 - val_loss: 9.4084 - val_mae: 2.1731\n",
      "Epoch 47/300\n",
      "1030/1030 [==============================] - 2s 2ms/step - loss: 8.4730 - mae: 2.0666 - val_loss: 9.4001 - val_mae: 2.1676\n",
      "Epoch 48/300\n",
      "1030/1030 [==============================] - 2s 2ms/step - loss: 8.4668 - mae: 2.0635 - val_loss: 9.3940 - val_mae: 2.1719\n",
      "Epoch 49/300\n",
      "1030/1030 [==============================] - 2s 2ms/step - loss: 8.4601 - mae: 2.0630 - val_loss: 9.3902 - val_mae: 2.1749\n",
      "Epoch 50/300\n",
      "1030/1030 [==============================] - 2s 2ms/step - loss: 8.4541 - mae: 2.0661 - val_loss: 9.3836 - val_mae: 2.1724\n",
      "Epoch 51/300\n",
      "1030/1030 [==============================] - 2s 2ms/step - loss: 8.4477 - mae: 2.0655 - val_loss: 9.3773 - val_mae: 2.1718\n",
      "Epoch 52/300\n",
      "1030/1030 [==============================] - 2s 2ms/step - loss: 8.4417 - mae: 2.0656 - val_loss: 9.3718 - val_mae: 2.1682\n",
      "Epoch 53/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.4356 - mae: 2.0631 - val_loss: 9.3677 - val_mae: 2.1736\n",
      "Epoch 54/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.4298 - mae: 2.0650 - val_loss: 9.3620 - val_mae: 2.1725\n",
      "Epoch 55/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.4239 - mae: 2.0666 - val_loss: 9.3559 - val_mae: 2.1661\n",
      "Epoch 56/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.4181 - mae: 2.0636 - val_loss: 9.3505 - val_mae: 2.1660\n",
      "Epoch 57/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.4124 - mae: 2.0606 - val_loss: 9.3448 - val_mae: 2.1732\n",
      "Epoch 58/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.4069 - mae: 2.0643 - val_loss: 9.3417 - val_mae: 2.1741\n",
      "Epoch 59/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.4016 - mae: 2.0670 - val_loss: 9.3361 - val_mae: 2.1686\n",
      "Epoch 60/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.3963 - mae: 2.0626 - val_loss: 9.3314 - val_mae: 2.1701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.3908 - mae: 2.0653 - val_loss: 9.3272 - val_mae: 2.1697\n",
      "Epoch 62/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.3857 - mae: 2.0638 - val_loss: 9.3204 - val_mae: 2.1675\n",
      "Epoch 63/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.3804 - mae: 2.0629 - val_loss: 9.3177 - val_mae: 2.1715\n",
      "Epoch 64/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.3758 - mae: 2.0652 - val_loss: 9.3135 - val_mae: 2.1689\n",
      "Epoch 65/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.3698 - mae: 2.0598 - val_loss: 9.3076 - val_mae: 2.1761\n",
      "Epoch 66/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.3657 - mae: 2.0660 - val_loss: 9.3030 - val_mae: 2.1702\n",
      "Epoch 67/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.3608 - mae: 2.0664 - val_loss: 9.2982 - val_mae: 2.1652\n",
      "Epoch 68/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.3564 - mae: 2.0620 - val_loss: 9.2944 - val_mae: 2.1690\n",
      "Epoch 69/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.3515 - mae: 2.0629 - val_loss: 9.2902 - val_mae: 2.1705\n",
      "Epoch 70/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.3468 - mae: 2.0649 - val_loss: 9.2860 - val_mae: 2.1686\n",
      "Epoch 71/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.3426 - mae: 2.0634 - val_loss: 9.2825 - val_mae: 2.1689\n",
      "Epoch 72/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.3377 - mae: 2.0652 - val_loss: 9.2773 - val_mae: 2.1637\n",
      "Epoch 73/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.3337 - mae: 2.0598 - val_loss: 9.2754 - val_mae: 2.1753\n",
      "Epoch 74/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.3296 - mae: 2.0652 - val_loss: 9.2727 - val_mae: 2.1735\n",
      "Epoch 75/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.3251 - mae: 2.0644 - val_loss: 9.2680 - val_mae: 2.1712\n",
      "Epoch 76/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.3210 - mae: 2.0623 - val_loss: 9.2669 - val_mae: 2.1747\n",
      "Epoch 77/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.3169 - mae: 2.0631 - val_loss: 9.2617 - val_mae: 2.1752\n",
      "Epoch 78/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.3129 - mae: 2.0637 - val_loss: 9.2582 - val_mae: 2.1735\n",
      "Epoch 79/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.3092 - mae: 2.0648 - val_loss: 9.2550 - val_mae: 2.1724\n",
      "Epoch 80/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.3054 - mae: 2.0626 - val_loss: 9.2512 - val_mae: 2.1735\n",
      "Epoch 81/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.3011 - mae: 2.0651 - val_loss: 9.2506 - val_mae: 2.1710\n",
      "Epoch 82/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.2976 - mae: 2.0634 - val_loss: 9.2443 - val_mae: 2.1675\n",
      "Epoch 83/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.2932 - mae: 2.0659 - val_loss: 9.2410 - val_mae: 2.1598\n",
      "Epoch 84/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.2902 - mae: 2.0599 - val_loss: 9.2421 - val_mae: 2.1713\n",
      "Epoch 85/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.2862 - mae: 2.0593 - val_loss: 9.2391 - val_mae: 2.1792\n",
      "Epoch 86/300\n",
      "1030/1030 [==============================] - 2s 2ms/step - loss: 8.2834 - mae: 2.0662 - val_loss: 9.2318 - val_mae: 2.1688\n",
      "Epoch 87/300\n",
      "1030/1030 [==============================] - 2s 2ms/step - loss: 8.2795 - mae: 2.0614 - val_loss: 9.2319 - val_mae: 2.1747\n",
      "Epoch 88/300\n",
      "1030/1030 [==============================] - 2s 1ms/step - loss: 8.2759 - mae: 2.0606 - val_loss: 9.2311 - val_mae: 2.1813\n",
      "Epoch 89/300\n",
      "1030/1030 [==============================] - 2s 2ms/step - loss: 8.2731 - mae: 2.0649 - val_loss: 9.2249 - val_mae: 2.1747\n",
      "Epoch 90/300\n",
      "1030/1030 [==============================] - 2s 2ms/step - loss: 8.2694 - mae: 2.0643 - val_loss: 9.2205 - val_mae: 2.1702\n",
      "Epoch 91/300\n",
      "1030/1030 [==============================] - 2s 2ms/step - loss: 8.2656 - mae: 2.0644 - val_loss: 9.2178 - val_mae: 2.1630\n",
      "Epoch 92/300\n",
      "1030/1030 [==============================] - 2s 2ms/step - loss: 8.2628 - mae: 2.0612 - val_loss: 9.2146 - val_mae: 2.1668\n",
      "Epoch 93/300\n",
      "1030/1030 [==============================] - 2s 2ms/step - loss: 8.2599 - mae: 2.0635 - val_loss: 9.2141 - val_mae: 2.1680\n",
      "Epoch 94/300\n",
      "1030/1030 [==============================] - 2s 1ms/step - loss: 8.2566 - mae: 2.0628 - val_loss: 9.2103 - val_mae: 2.1654\n",
      "Epoch 95/300\n",
      "1030/1030 [==============================] - 2s 2ms/step - loss: 8.2536 - mae: 2.0618 - val_loss: 9.2065 - val_mae: 2.1680\n",
      "Epoch 96/300\n",
      "1030/1030 [==============================] - 2s 2ms/step - loss: 8.2509 - mae: 2.0620 - val_loss: 9.2057 - val_mae: 2.1693\n",
      "Epoch 97/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.2479 - mae: 2.0635 - val_loss: 9.2032 - val_mae: 2.1685\n",
      "Epoch 98/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.2446 - mae: 2.0611 - val_loss: 9.2023 - val_mae: 2.1727\n",
      "Epoch 99/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.2416 - mae: 2.0654 - val_loss: 9.1977 - val_mae: 2.1640\n",
      "Epoch 100/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.2395 - mae: 2.0589 - val_loss: 9.1983 - val_mae: 2.1767\n",
      "Epoch 101/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.2364 - mae: 2.0652 - val_loss: 9.1947 - val_mae: 2.1689\n",
      "Epoch 102/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.2335 - mae: 2.0634 - val_loss: 9.1919 - val_mae: 2.1660\n",
      "Epoch 103/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.2312 - mae: 2.0615 - val_loss: 9.1907 - val_mae: 2.1695\n",
      "Epoch 104/300\n",
      "1030/1030 [==============================] - 2s 2ms/step - loss: 8.2281 - mae: 2.0619 - val_loss: 9.1888 - val_mae: 2.1722\n",
      "Epoch 105/300\n",
      "1030/1030 [==============================] - 2s 2ms/step - loss: 8.2252 - mae: 2.0641 - val_loss: 9.1859 - val_mae: 2.1670\n",
      "Epoch 106/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.2229 - mae: 2.0619 - val_loss: 9.1836 - val_mae: 2.1670\n",
      "Epoch 107/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.2203 - mae: 2.0602 - val_loss: 9.1809 - val_mae: 2.1717\n",
      "Epoch 108/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.2177 - mae: 2.0633 - val_loss: 9.1808 - val_mae: 2.1733\n",
      "Epoch 109/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.2154 - mae: 2.0619 - val_loss: 9.1790 - val_mae: 2.1733\n",
      "Epoch 110/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.2129 - mae: 2.0633 - val_loss: 9.1752 - val_mae: 2.1707\n",
      "Epoch 111/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.2104 - mae: 2.0623 - val_loss: 9.1721 - val_mae: 2.1689\n",
      "Epoch 112/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.2078 - mae: 2.0616 - val_loss: 9.1728 - val_mae: 2.1727\n",
      "Epoch 113/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.2055 - mae: 2.0628 - val_loss: 9.1705 - val_mae: 2.1718\n",
      "Epoch 114/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.2029 - mae: 2.0600 - val_loss: 9.1712 - val_mae: 2.1782\n",
      "Epoch 115/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.2010 - mae: 2.0650 - val_loss: 9.1664 - val_mae: 2.1685\n",
      "Epoch 116/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1985 - mae: 2.0599 - val_loss: 9.1633 - val_mae: 2.1727\n",
      "Epoch 117/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1961 - mae: 2.0628 - val_loss: 9.1613 - val_mae: 2.1701\n",
      "Epoch 118/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1940 - mae: 2.0614 - val_loss: 9.1605 - val_mae: 2.1739\n",
      "Epoch 119/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1915 - mae: 2.0642 - val_loss: 9.1571 - val_mae: 2.1657\n",
      "Epoch 120/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1893 - mae: 2.0597 - val_loss: 9.1578 - val_mae: 2.1742\n",
      "Epoch 121/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1873 - mae: 2.0634 - val_loss: 9.1567 - val_mae: 2.1736\n",
      "Epoch 122/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1852 - mae: 2.0623 - val_loss: 9.1560 - val_mae: 2.1753\n",
      "Epoch 123/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1826 - mae: 2.0649 - val_loss: 9.1530 - val_mae: 2.1664\n",
      "Epoch 124/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1813 - mae: 2.0589 - val_loss: 9.1498 - val_mae: 2.1715\n",
      "Epoch 125/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1791 - mae: 2.0637 - val_loss: 9.1473 - val_mae: 2.1677\n",
      "Epoch 126/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1767 - mae: 2.0586 - val_loss: 9.1464 - val_mae: 2.1769\n",
      "Epoch 127/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1749 - mae: 2.0643 - val_loss: 9.1440 - val_mae: 2.1704\n",
      "Epoch 128/300\n",
      "1030/1030 [==============================] - 2s 2ms/step - loss: 8.1731 - mae: 2.0612 - val_loss: 9.1404 - val_mae: 2.1714\n",
      "Epoch 129/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1707 - mae: 2.0602 - val_loss: 9.1406 - val_mae: 2.1759\n",
      "Epoch 130/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1685 - mae: 2.0625 - val_loss: 9.1382 - val_mae: 2.1721\n",
      "Epoch 131/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1669 - mae: 2.0624 - val_loss: 9.1357 - val_mae: 2.1694\n",
      "Epoch 132/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1650 - mae: 2.0624 - val_loss: 9.1347 - val_mae: 2.1691\n",
      "Epoch 133/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1630 - mae: 2.0593 - val_loss: 9.1351 - val_mae: 2.1770\n",
      "Epoch 134/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1612 - mae: 2.0623 - val_loss: 9.1317 - val_mae: 2.1742\n",
      "Epoch 135/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1591 - mae: 2.0603 - val_loss: 9.1304 - val_mae: 2.1763\n",
      "Epoch 136/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1575 - mae: 2.0641 - val_loss: 9.1282 - val_mae: 2.1710- loss: 8.1140 - mae: 2.0\n",
      "Epoch 137/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1555 - mae: 2.0619 - val_loss: 9.1256 - val_mae: 2.1692\n",
      "Epoch 138/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1539 - mae: 2.0600 - val_loss: 9.1242 - val_mae: 2.1722\n",
      "Epoch 139/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1519 - mae: 2.0614 - val_loss: 9.1232 - val_mae: 2.1730\n",
      "Epoch 140/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1501 - mae: 2.0604 - val_loss: 9.1246 - val_mae: 2.1779\n",
      "Epoch 141/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1486 - mae: 2.0641 - val_loss: 9.1196 - val_mae: 2.1660\n",
      "Epoch 142/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1468 - mae: 2.0602 - val_loss: 9.1182 - val_mae: 2.1706\n",
      "Epoch 143/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1443 - mae: 2.0599 - val_loss: 9.1217 - val_mae: 2.1785\n",
      "Epoch 144/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1439 - mae: 2.0631 - val_loss: 9.1153 - val_mae: 2.1710\n",
      "Epoch 145/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1416 - mae: 2.0617 - val_loss: 9.1162 - val_mae: 2.1730\n",
      "Epoch 146/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1400 - mae: 2.0632 - val_loss: 9.1131 - val_mae: 2.1677\n",
      "Epoch 147/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1384 - mae: 2.0595 - val_loss: 9.1115 - val_mae: 2.1713\n",
      "Epoch 148/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1366 - mae: 2.0623 - val_loss: 9.1111 - val_mae: 2.1697\n",
      "Epoch 149/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1350 - mae: 2.0595 - val_loss: 9.1113 - val_mae: 2.1745\n",
      "Epoch 150/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1337 - mae: 2.0610 - val_loss: 9.1090 - val_mae: 2.1751loss: 8.1175 - mae: 2.05\n",
      "Epoch 151/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1317 - mae: 2.0605 - val_loss: 9.1093 - val_mae: 2.1757\n",
      "Epoch 152/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1302 - mae: 2.0638 - val_loss: 9.1058 - val_mae: 2.1679\n",
      "Epoch 153/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1290 - mae: 2.0614 - val_loss: 9.1036 - val_mae: 2.1666\n",
      "Epoch 154/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1272 - mae: 2.0593 - val_loss: 9.1034 - val_mae: 2.1730\n",
      "Epoch 155/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1258 - mae: 2.0608 - val_loss: 9.1011 - val_mae: 2.1729\n",
      "Epoch 156/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1240 - mae: 2.0623 - val_loss: 9.0979 - val_mae: 2.1653\n",
      "Epoch 157/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1231 - mae: 2.0609 - val_loss: 9.0973 - val_mae: 2.1681\n",
      "Epoch 158/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1209 - mae: 2.0584 - val_loss: 9.1002 - val_mae: 2.1796\n",
      "Epoch 159/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1200 - mae: 2.0644 - val_loss: 9.0976 - val_mae: 2.1693\n",
      "Epoch 160/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1183 - mae: 2.0627 - val_loss: 9.0944 - val_mae: 2.1626\n",
      "Epoch 161/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1167 - mae: 2.0605 - val_loss: 9.0925 - val_mae: 2.1625\n",
      "Epoch 162/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1150 - mae: 2.0590 - val_loss: 9.0952 - val_mae: 2.1729\n",
      "Epoch 163/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1140 - mae: 2.0630 - val_loss: 9.0904 - val_mae: 2.1655\n",
      "Epoch 164/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1129 - mae: 2.0597 - val_loss: 9.0898 - val_mae: 2.1698\n",
      "Epoch 165/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1111 - mae: 2.0614 - val_loss: 9.0883 - val_mae: 2.1684\n",
      "Epoch 166/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1102 - mae: 2.0597 - val_loss: 9.0902 - val_mae: 2.1751\n",
      "Epoch 167/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1086 - mae: 2.0642 - val_loss: 9.0873 - val_mae: 2.1653\n",
      "Epoch 168/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1072 - mae: 2.0575 - val_loss: 9.0859 - val_mae: 2.1728\n",
      "Epoch 169/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1060 - mae: 2.0612 - val_loss: 9.0853 - val_mae: 2.1724\n",
      "Epoch 170/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1044 - mae: 2.0606 - val_loss: 9.0858 - val_mae: 2.1765TA: 0s - loss: 8.0006 - mae\n",
      "Epoch 171/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1030 - mae: 2.0615 - val_loss: 9.0828 - val_mae: 2.1714\n",
      "Epoch 172/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1015 - mae: 2.0630 - val_loss: 9.0811 - val_mae: 2.1660\n",
      "Epoch 173/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.1005 - mae: 2.0590 - val_loss: 9.0797 - val_mae: 2.1684\n",
      "Epoch 174/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0986 - mae: 2.0626 - val_loss: 9.0776 - val_mae: 2.1647\n",
      "Epoch 175/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0979 - mae: 2.0589 - val_loss: 9.0787 - val_mae: 2.1716\n",
      "Epoch 176/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0968 - mae: 2.0612 - val_loss: 9.0785 - val_mae: 2.1713\n",
      "Epoch 177/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0960 - mae: 2.0605 - val_loss: 9.0763 - val_mae: 2.1705\n",
      "Epoch 178/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0943 - mae: 2.0591 - val_loss: 9.0770 - val_mae: 2.1744\n",
      "Epoch 179/300\n",
      "1030/1030 [==============================] - 2s 1ms/step - loss: 8.0931 - mae: 2.0612 - val_loss: 9.0767 - val_mae: 2.1741\n",
      "Epoch 180/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0922 - mae: 2.0613 - val_loss: 9.0756 - val_mae: 2.1717\n",
      "Epoch 181/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0904 - mae: 2.0611 - val_loss: 9.0717 - val_mae: 2.1685\n",
      "Epoch 182/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0896 - mae: 2.0594 - val_loss: 9.0732 - val_mae: 2.1722\n",
      "Epoch 183/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0883 - mae: 2.0624 - val_loss: 9.0738 - val_mae: 2.1710\n",
      "Epoch 184/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0869 - mae: 2.0597 - val_loss: 9.0696 - val_mae: 2.1685\n",
      "Epoch 185/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0857 - mae: 2.0579 - val_loss: 9.0724 - val_mae: 2.1792\n",
      "Epoch 186/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0847 - mae: 2.0619 - val_loss: 9.0670 - val_mae: 2.1703\n",
      "Epoch 187/300\n",
      "1030/1030 [==============================] - 2s 1ms/step - loss: 8.0838 - mae: 2.0612 - val_loss: 9.0668 - val_mae: 2.1690\n",
      "Epoch 188/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0829 - mae: 2.0596 - val_loss: 9.0681 - val_mae: 2.1762\n",
      "Epoch 189/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0815 - mae: 2.0617 - val_loss: 9.0688 - val_mae: 2.1748\n",
      "Epoch 190/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0806 - mae: 2.0611 - val_loss: 9.0649 - val_mae: 2.1680\n",
      "Epoch 191/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0799 - mae: 2.0602 - val_loss: 9.0641 - val_mae: 2.1692\n",
      "Epoch 192/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0783 - mae: 2.0628 - val_loss: 9.0641 - val_mae: 2.1654\n",
      "Epoch 193/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0775 - mae: 2.0589 - val_loss: 9.0655 - val_mae: 2.1721\n",
      "Epoch 194/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0766 - mae: 2.0621 - val_loss: 9.0624 - val_mae: 2.1667\n",
      "Epoch 195/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0758 - mae: 2.0583 - val_loss: 9.0622 - val_mae: 2.1725\n",
      "Epoch 196/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0747 - mae: 2.0598 - val_loss: 9.0604 - val_mae: 2.1741\n",
      "Epoch 197/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0737 - mae: 2.0633 - val_loss: 9.0591 - val_mae: 2.1666\n",
      "Epoch 198/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0727 - mae: 2.0586 - val_loss: 9.0580 - val_mae: 2.1685\n",
      "Epoch 199/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0717 - mae: 2.0607 - val_loss: 9.0586 - val_mae: 2.1691\n",
      "Epoch 200/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0708 - mae: 2.0606 - val_loss: 9.0583 - val_mae: 2.1727\n",
      "Epoch 201/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0698 - mae: 2.0586 - val_loss: 9.0590 - val_mae: 2.1782\n",
      "Epoch 202/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0690 - mae: 2.0626 - val_loss: 9.0567 - val_mae: 2.1712\n",
      "Epoch 203/300\n",
      "1030/1030 [==============================] - 1s 1000us/step - loss: 8.0677 - mae: 2.0586 - val_loss: 9.0562 - val_mae: 2.1762\n",
      "Epoch 204/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0668 - mae: 2.0619 - val_loss: 9.0562 - val_mae: 2.1755\n",
      "Epoch 205/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0659 - mae: 2.0607 - val_loss: 9.0541 - val_mae: 2.1719\n",
      "Epoch 206/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0650 - mae: 2.0622 - val_loss: 9.0539 - val_mae: 2.1693\n",
      "Epoch 207/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0634 - mae: 2.0590 - val_loss: 9.0545 - val_mae: 2.1738\n",
      "Epoch 208/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0624 - mae: 2.0622 - val_loss: 9.0509 - val_mae: 2.1634\n",
      "Epoch 209/300\n",
      "1030/1030 [==============================] - 1s 1000us/step - loss: 8.0621 - mae: 2.0572 - val_loss: 9.0532 - val_mae: 2.1784\n",
      "Epoch 210/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0609 - mae: 2.0600 - val_loss: 9.0536 - val_mae: 2.1812\n",
      "Epoch 211/300\n",
      "1030/1030 [==============================] - 1s 990us/step - loss: 8.0600 - mae: 2.0638 - val_loss: 9.0511 - val_mae: 2.1702\n",
      "Epoch 212/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0597 - mae: 2.0593 - val_loss: 9.0508 - val_mae: 2.1732\n",
      "Epoch 213/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0576 - mae: 2.0639 - val_loss: 9.0481 - val_mae: 2.1605\n",
      "Epoch 214/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0577 - mae: 2.0569 - val_loss: 9.0461 - val_mae: 2.1669\n",
      "Epoch 215/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0567 - mae: 2.0622 - val_loss: 9.0467 - val_mae: 2.1643\n",
      "Epoch 216/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0557 - mae: 2.0579 - val_loss: 9.0471 - val_mae: 2.1723\n",
      "Epoch 217/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0548 - mae: 2.0582 - val_loss: 9.0486 - val_mae: 2.1778\n",
      "Epoch 218/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0542 - mae: 2.0641 - val_loss: 9.0455 - val_mae: 2.1650\n",
      "Epoch 219/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0533 - mae: 2.0576 - val_loss: 9.0455 - val_mae: 2.1741\n",
      "Epoch 220/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0524 - mae: 2.0595 - val_loss: 9.0454 - val_mae: 2.1759\n",
      "Epoch 221/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0521 - mae: 2.0617 - val_loss: 9.0442 - val_mae: 2.1717\n",
      "Epoch 222/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0511 - mae: 2.0589 - val_loss: 9.0440 - val_mae: 2.1765\n",
      "Epoch 223/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0507 - mae: 2.0615 - val_loss: 9.0431 - val_mae: 2.1736\n",
      "Epoch 224/300\n",
      "1030/1030 [==============================] - 2s 2ms/step - loss: 8.0495 - mae: 2.0586 - val_loss: 9.0423 - val_mae: 2.1758\n",
      "Epoch 225/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0489 - mae: 2.0628 - val_loss: 9.0417 - val_mae: 2.1688\n",
      "Epoch 226/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0483 - mae: 2.0587 - val_loss: 9.0414 - val_mae: 2.1717\n",
      "Epoch 227/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0475 - mae: 2.0592 - val_loss: 9.0406 - val_mae: 2.1741\n",
      "Epoch 228/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0466 - mae: 2.0606 - val_loss: 9.0413 - val_mae: 2.1755\n",
      "Epoch 229/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0466 - mae: 2.0608 - val_loss: 9.0397 - val_mae: 2.1702\n",
      "Epoch 230/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0455 - mae: 2.0599 - val_loss: 9.0399 - val_mae: 2.1740\n",
      "Epoch 231/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0447 - mae: 2.0627 - val_loss: 9.0399 - val_mae: 2.1666\n",
      "Epoch 232/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0439 - mae: 2.0579 - val_loss: 9.0417 - val_mae: 2.1756\n",
      "Epoch 233/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0430 - mae: 2.0625 - val_loss: 9.0372 - val_mae: 2.1645\n",
      "Epoch 234/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0430 - mae: 2.0575 - val_loss: 9.0400 - val_mae: 2.1752\n",
      "Epoch 235/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0422 - mae: 2.0594 - val_loss: 9.0375 - val_mae: 2.1753\n",
      "Epoch 236/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0414 - mae: 2.0608 - val_loss: 9.0351 - val_mae: 2.1702\n",
      "Epoch 237/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0402 - mae: 2.0620 - val_loss: 9.0349 - val_mae: 2.1609\n",
      "Epoch 238/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0402 - mae: 2.0573 - val_loss: 9.0336 - val_mae: 2.1734\n",
      "Epoch 239/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0396 - mae: 2.0603 - val_loss: 9.0326 - val_mae: 2.1698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0389 - mae: 2.0598 - val_loss: 9.0350 - val_mae: 2.1737\n",
      "Epoch 241/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0375 - mae: 2.0623 - val_loss: 9.0317 - val_mae: 2.1639\n",
      "Epoch 242/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0377 - mae: 2.0589 - val_loss: 9.0323 - val_mae: 2.1656\n",
      "Epoch 243/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0366 - mae: 2.0577 - val_loss: 9.0351 - val_mae: 2.1776\n",
      "Epoch 244/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0364 - mae: 2.0598 - val_loss: 9.0344 - val_mae: 2.1761\n",
      "Epoch 245/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0355 - mae: 2.0575 - val_loss: 9.0338 - val_mae: 2.1815\n",
      "Epoch 246/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0353 - mae: 2.0623 - val_loss: 9.0300 - val_mae: 2.1740\n",
      "Epoch 247/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0346 - mae: 2.0597 - val_loss: 9.0298 - val_mae: 2.1743\n",
      "Epoch 248/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0336 - mae: 2.0605 - val_loss: 9.0305 - val_mae: 2.1728\n",
      "Epoch 249/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0328 - mae: 2.0616 - val_loss: 9.0279 - val_mae: 2.1635\n",
      "Epoch 250/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0328 - mae: 2.0572 - val_loss: 9.0307 - val_mae: 2.1747\n",
      "Epoch 251/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0319 - mae: 2.0593 - val_loss: 9.0322 - val_mae: 2.1784\n",
      "Epoch 252/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0314 - mae: 2.0617 - val_loss: 9.0279 - val_mae: 2.1690\n",
      "Epoch 253/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0306 - mae: 2.0585 - val_loss: 9.0302 - val_mae: 2.1748\n",
      "Epoch 254/300\n",
      "1030/1030 [==============================] - 1s 995us/step - loss: 8.0307 - mae: 2.0599 - val_loss: 9.0278 - val_mae: 2.1741\n",
      "Epoch 255/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0298 - mae: 2.0590 - val_loss: 9.0278 - val_mae: 2.1778\n",
      "Epoch 256/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0295 - mae: 2.0612 - val_loss: 9.0260 - val_mae: 2.1721\n",
      "Epoch 257/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0286 - mae: 2.0603 - val_loss: 9.0257 - val_mae: 2.1708\n",
      "Epoch 258/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0281 - mae: 2.0591 - val_loss: 9.0258 - val_mae: 2.1726\n",
      "Epoch 259/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0262 - mae: 2.0569 - val_loss: 9.0356 - val_mae: 2.1883\n",
      "Epoch 260/300\n",
      "1030/1030 [==============================] - 2s 2ms/step - loss: 8.0279 - mae: 2.0612 - val_loss: 9.0268 - val_mae: 2.1760\n",
      "Epoch 261/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0266 - mae: 2.0595 - val_loss: 9.0280 - val_mae: 2.1781\n",
      "Epoch 262/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0267 - mae: 2.0623 - val_loss: 9.0246 - val_mae: 2.1678\n",
      "Epoch 263/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0257 - mae: 2.0582 - val_loss: 9.0242 - val_mae: 2.1744\n",
      "Epoch 264/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0254 - mae: 2.0606 - val_loss: 9.0241 - val_mae: 2.1714\n",
      "Epoch 265/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0248 - mae: 2.0605 - val_loss: 9.0224 - val_mae: 2.1662\n",
      "Epoch 266/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0242 - mae: 2.0569 - val_loss: 9.0243 - val_mae: 2.1769\n",
      "Epoch 267/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0235 - mae: 2.0593 - val_loss: 9.0240 - val_mae: 2.1779\n",
      "Epoch 268/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0233 - mae: 2.0629 - val_loss: 9.0224 - val_mae: 2.1656\n",
      "Epoch 269/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0233 - mae: 2.0585 - val_loss: 9.0218 - val_mae: 2.1723\n",
      "Epoch 270/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0222 - mae: 2.0604 - val_loss: 9.0218 - val_mae: 2.1670\n",
      "Epoch 271/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0222 - mae: 2.0584 - val_loss: 9.0208 - val_mae: 2.1708\n",
      "Epoch 272/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0216 - mae: 2.0595 - val_loss: 9.0217 - val_mae: 2.1725\n",
      "Epoch 273/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0211 - mae: 2.0581 - val_loss: 9.0223 - val_mae: 2.1777\n",
      "Epoch 274/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0204 - mae: 2.0605 - val_loss: 9.0227 - val_mae: 2.1772\n",
      "Epoch 275/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0197 - mae: 2.0604 - val_loss: 9.0194 - val_mae: 2.1682\n",
      "Epoch 276/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0191 - mae: 2.0571 - val_loss: 9.0214 - val_mae: 2.1775\n",
      "Epoch 277/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0185 - mae: 2.0588 - val_loss: 9.0204 - val_mae: 2.1783\n",
      "Epoch 278/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0181 - mae: 2.0583 - val_loss: 9.0237 - val_mae: 2.1838\n",
      "Epoch 279/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0184 - mae: 2.0633 - val_loss: 9.0184 - val_mae: 2.1686\n",
      "Epoch 280/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0175 - mae: 2.0590 - val_loss: 9.0203 - val_mae: 2.1735\n",
      "Epoch 281/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0173 - mae: 2.0613 - val_loss: 9.0179 - val_mae: 2.1673\n",
      "Epoch 282/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0167 - mae: 2.0597 - val_loss: 9.0182 - val_mae: 2.1657\n",
      "Epoch 283/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0166 - mae: 2.0587 - val_loss: 9.0176 - val_mae: 2.1709\n",
      "Epoch 284/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0157 - mae: 2.0590 - val_loss: 9.0174 - val_mae: 2.1739\n",
      "Epoch 285/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0159 - mae: 2.0600 - val_loss: 9.0181 - val_mae: 2.1741\n",
      "Epoch 286/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0154 - mae: 2.0592 - val_loss: 9.0173 - val_mae: 2.1726\n",
      "Epoch 287/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0141 - mae: 2.0579 - val_loss: 9.0178 - val_mae: 2.1788\n",
      "Epoch 288/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0143 - mae: 2.0608 - val_loss: 9.0165 - val_mae: 2.1734\n",
      "Epoch 289/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0136 - mae: 2.0595 - val_loss: 9.0180 - val_mae: 2.1747\n",
      "Epoch 290/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0131 - mae: 2.0590 - val_loss: 9.0181 - val_mae: 2.1776\n",
      "Epoch 291/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0131 - mae: 2.0599 - val_loss: 9.0168 - val_mae: 2.1742\n",
      "Epoch 292/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0126 - mae: 2.0603 - val_loss: 9.0162 - val_mae: 2.1717\n",
      "Epoch 293/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0124 - mae: 2.0601 - val_loss: 9.0145 - val_mae: 2.1700\n",
      "Epoch 294/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0116 - mae: 2.0581 - val_loss: 9.0133 - val_mae: 2.1698\n",
      "Epoch 295/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0117 - mae: 2.0594 - val_loss: 9.0141 - val_mae: 2.1743\n",
      "Epoch 296/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0109 - mae: 2.0597 - val_loss: 9.0162 - val_mae: 2.1732\n",
      "Epoch 297/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0101 - mae: 2.0569 - val_loss: 9.0186 - val_mae: 2.1841\n",
      "Epoch 298/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0109 - mae: 2.0623 - val_loss: 9.0166 - val_mae: 2.1777\n",
      "Epoch 299/300\n",
      "1030/1030 [==============================] - 1s 1ms/step - loss: 8.0098 - mae: 2.0616 - val_loss: 9.0148 - val_mae: 2.1692\n"
     ]
    }
   ],
   "source": [
    "model = init_model(27,learn = 0.00003)\n",
    "es = EarlyStopping(patience=5)\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train, \n",
    "                  batch_size=32, \n",
    "                  epochs=300, \n",
    "                  validation_split=0.3,\n",
    "                  callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dd9ce28d",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 0s 861us/step - loss: 8.4447 - mae: 2.1063\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8.444677352905273, 2.1062543392181396]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_eval = model.evaluate(X_test_scaled, y_test)\n",
    "y_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831d195a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Score = 1.09 -------   layers 35, 25, 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bb11ecf",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "players_data = full_data[full_data['minutes'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bea88ffa",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of positions = 4\n",
      "Index(['r_assists', 'r_bonus', 'r_bps', 'r_clean_sheets', 'r_creativity',\n",
      "       'r_goals_conceded', 'r_threat', 'r_goals_scored', 'r_ict_index',\n",
      "       'r_influence', 'r_minutes', 'r_own_goals', 'r_penalties_missed',\n",
      "       'r_penalties_saved', 'r_red_cards', 'r_saves', 'r_transfers_balance',\n",
      "       'r_value', 'r_yellow_cards', 'r_team_a_score', 'r_team_h_score',\n",
      "       'r_total_points', 'was_home', 'DEF', 'FWD', 'GK', 'MID'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(104005, 27)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop = [\"name\",\"level_1\",\"season\",\"position\",\"GW\"]\n",
    "roll = 2\n",
    "\n",
    "X_train_scaled, X_test_scaled, y_train, y_test = model_ready(full_data, drop, roll)\n",
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5da803ab",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 9.2848 - mae: 1.4255 - val_loss: 7.9817 - val_mae: 1.3745\n",
      "Epoch 2/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 6.9493 - mae: 1.3020 - val_loss: 7.2430 - val_mae: 1.3372\n",
      "Epoch 3/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 6.4993 - mae: 1.2646 - val_loss: 6.8651 - val_mae: 1.3114\n",
      "Epoch 4/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 6.2055 - mae: 1.2460 - val_loss: 6.6049 - val_mae: 1.3024\n",
      "Epoch 5/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 6.0007 - mae: 1.2353 - val_loss: 6.4251 - val_mae: 1.2944\n",
      "Epoch 6/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 5.8526 - mae: 1.2307 - val_loss: 6.2920 - val_mae: 1.2903\n",
      "Epoch 7/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 5.7380 - mae: 1.2275 - val_loss: 6.1859 - val_mae: 1.2920\n",
      "Epoch 8/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 5.6437 - mae: 1.2267 - val_loss: 6.1020 - val_mae: 1.2876\n",
      "Epoch 9/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 5.5672 - mae: 1.2253 - val_loss: 6.0287 - val_mae: 1.2868\n",
      "Epoch 10/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 5.4991 - mae: 1.2253 - val_loss: 5.9659 - val_mae: 1.2784\n",
      "Epoch 11/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 5.4399 - mae: 1.2225 - val_loss: 5.9073 - val_mae: 1.2808\n",
      "Epoch 12/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 5.3848 - mae: 1.2222 - val_loss: 5.8546 - val_mae: 1.2771\n",
      "Epoch 13/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 5.3345 - mae: 1.2198 - val_loss: 5.8066 - val_mae: 1.2819\n",
      "Epoch 14/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 5.2896 - mae: 1.2186 - val_loss: 5.7640 - val_mae: 1.2924\n",
      "Epoch 15/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 5.2484 - mae: 1.2205 - val_loss: 5.7244 - val_mae: 1.2878\n",
      "Epoch 16/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 5.2117 - mae: 1.2207 - val_loss: 5.6916 - val_mae: 1.2864\n",
      "Epoch 17/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 5.1786 - mae: 1.2192 - val_loss: 5.6578 - val_mae: 1.2780\n",
      "Epoch 18/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 5.1480 - mae: 1.2169 - val_loss: 5.6308 - val_mae: 1.2978\n",
      "Epoch 19/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 5.1185 - mae: 1.2186 - val_loss: 5.6056 - val_mae: 1.3006\n",
      "Epoch 20/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 5.0925 - mae: 1.2198 - val_loss: 5.5724 - val_mae: 1.2775\n",
      "Epoch 21/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 5.0658 - mae: 1.2153 - val_loss: 5.5475 - val_mae: 1.2891\n",
      "Epoch 22/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 5.0414 - mae: 1.2178 - val_loss: 5.5239 - val_mae: 1.2854\n",
      "Epoch 23/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 5.0171 - mae: 1.2166 - val_loss: 5.5009 - val_mae: 1.2842\n",
      "Epoch 24/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.9966 - mae: 1.2173 - val_loss: 5.4820 - val_mae: 1.2913\n",
      "Epoch 25/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.9760 - mae: 1.2178 - val_loss: 5.4593 - val_mae: 1.2787\n",
      "Epoch 26/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.9560 - mae: 1.2145 - val_loss: 5.4428 - val_mae: 1.2952\n",
      "Epoch 27/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.9377 - mae: 1.2188 - val_loss: 5.4226 - val_mae: 1.2692\n",
      "Epoch 28/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.9201 - mae: 1.2163 - val_loss: 5.4061 - val_mae: 1.2673\n",
      "Epoch 29/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.9038 - mae: 1.2150 - val_loss: 5.3905 - val_mae: 1.2790\n",
      "Epoch 30/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.8895 - mae: 1.2153 - val_loss: 5.3766 - val_mae: 1.2841\n",
      "Epoch 31/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.8756 - mae: 1.2158 - val_loss: 5.3638 - val_mae: 1.2806\n",
      "Epoch 32/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.8631 - mae: 1.2145 - val_loss: 5.3494 - val_mae: 1.2772\n",
      "Epoch 33/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.8499 - mae: 1.2155 - val_loss: 5.3364 - val_mae: 1.2732\n",
      "Epoch 34/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.8366 - mae: 1.2147 - val_loss: 5.3237 - val_mae: 1.2725\n",
      "Epoch 35/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.8247 - mae: 1.2134 - val_loss: 5.3147 - val_mae: 1.2860\n",
      "Epoch 36/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.8150 - mae: 1.2142 - val_loss: 5.3040 - val_mae: 1.2859\n",
      "Epoch 37/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.8055 - mae: 1.2152 - val_loss: 5.2950 - val_mae: 1.2849\n",
      "Epoch 38/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.7965 - mae: 1.2151 - val_loss: 5.2857 - val_mae: 1.2761\n",
      "Epoch 39/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.7879 - mae: 1.2148 - val_loss: 5.2780 - val_mae: 1.2776\n",
      "Epoch 40/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.7797 - mae: 1.2151 - val_loss: 5.2697 - val_mae: 1.2777\n",
      "Epoch 41/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.7719 - mae: 1.2139 - val_loss: 5.2624 - val_mae: 1.2856\n",
      "Epoch 42/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.7640 - mae: 1.2151 - val_loss: 5.2540 - val_mae: 1.2764\n",
      "Epoch 43/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.7567 - mae: 1.2150 - val_loss: 5.2465 - val_mae: 1.2701\n",
      "Epoch 44/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.7493 - mae: 1.2131 - val_loss: 5.2396 - val_mae: 1.2783\n",
      "Epoch 45/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.7425 - mae: 1.2138 - val_loss: 5.2327 - val_mae: 1.2833\n",
      "Epoch 46/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.7357 - mae: 1.2143 - val_loss: 5.2259 - val_mae: 1.2786\n",
      "Epoch 47/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.7292 - mae: 1.2130 - val_loss: 5.2197 - val_mae: 1.2805\n",
      "Epoch 48/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.7228 - mae: 1.2130 - val_loss: 5.2148 - val_mae: 1.2875\n",
      "Epoch 49/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.7170 - mae: 1.2147 - val_loss: 5.2066 - val_mae: 1.2728\n",
      "Epoch 50/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.7107 - mae: 1.2127 - val_loss: 5.2010 - val_mae: 1.2765\n",
      "Epoch 51/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.7044 - mae: 1.2133 - val_loss: 5.1963 - val_mae: 1.2661\n",
      "Epoch 52/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6989 - mae: 1.2120 - val_loss: 5.1904 - val_mae: 1.2800\n",
      "Epoch 53/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6929 - mae: 1.2126 - val_loss: 5.1840 - val_mae: 1.2807\n",
      "Epoch 54/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6865 - mae: 1.2129 - val_loss: 5.1764 - val_mae: 1.2771\n",
      "Epoch 55/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6800 - mae: 1.2115 - val_loss: 5.1725 - val_mae: 1.2884\n",
      "Epoch 56/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6748 - mae: 1.2131 - val_loss: 5.1658 - val_mae: 1.2793\n",
      "Epoch 57/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6706 - mae: 1.2121 - val_loss: 5.1626 - val_mae: 1.2693\n",
      "Epoch 58/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6671 - mae: 1.2112 - val_loss: 5.1582 - val_mae: 1.2756\n",
      "Epoch 59/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6633 - mae: 1.2131 - val_loss: 5.1544 - val_mae: 1.2636\n",
      "Epoch 60/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6598 - mae: 1.2103 - val_loss: 5.1524 - val_mae: 1.2787\n",
      "Epoch 61/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6561 - mae: 1.2118 - val_loss: 5.1478 - val_mae: 1.2732\n",
      "Epoch 62/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6530 - mae: 1.2109 - val_loss: 5.1448 - val_mae: 1.2749\n",
      "Epoch 63/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6497 - mae: 1.2098 - val_loss: 5.1419 - val_mae: 1.2835\n",
      "Epoch 64/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6466 - mae: 1.2120 - val_loss: 5.1389 - val_mae: 1.2785\n",
      "Epoch 65/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6438 - mae: 1.2103 - val_loss: 5.1371 - val_mae: 1.2859\n",
      "Epoch 66/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6410 - mae: 1.2123 - val_loss: 5.1332 - val_mae: 1.2724\n",
      "Epoch 67/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6384 - mae: 1.2117 - val_loss: 5.1312 - val_mae: 1.2767\n",
      "Epoch 68/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6357 - mae: 1.2111 - val_loss: 5.1281 - val_mae: 1.2735\n",
      "Epoch 69/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6333 - mae: 1.2104 - val_loss: 5.1282 - val_mae: 1.2859\n",
      "Epoch 70/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6307 - mae: 1.2121 - val_loss: 5.1241 - val_mae: 1.2663\n",
      "Epoch 71/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6286 - mae: 1.2100 - val_loss: 5.1217 - val_mae: 1.2715\n",
      "Epoch 72/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6264 - mae: 1.2104 - val_loss: 5.1193 - val_mae: 1.2760\n",
      "Epoch 73/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6238 - mae: 1.2093 - val_loss: 5.1190 - val_mae: 1.2892\n",
      "Epoch 74/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6216 - mae: 1.2103 - val_loss: 5.1178 - val_mae: 1.2870\n",
      "Epoch 75/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.6197 - mae: 1.2118 - val_loss: 5.1130 - val_mae: 1.2759\n",
      "Epoch 76/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6175 - mae: 1.2101 - val_loss: 5.1107 - val_mae: 1.2786\n",
      "Epoch 77/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6151 - mae: 1.2102 - val_loss: 5.1081 - val_mae: 1.2702\n",
      "Epoch 78/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6133 - mae: 1.2101 - val_loss: 5.1064 - val_mae: 1.2734\n",
      "Epoch 79/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6110 - mae: 1.2108 - val_loss: 5.1049 - val_mae: 1.2696\n",
      "Epoch 80/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6094 - mae: 1.2084 - val_loss: 5.1028 - val_mae: 1.2826\n",
      "Epoch 81/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6073 - mae: 1.2123 - val_loss: 5.1007 - val_mae: 1.2673\n",
      "Epoch 82/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6052 - mae: 1.2095 - val_loss: 5.0994 - val_mae: 1.2783\n",
      "Epoch 83/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6037 - mae: 1.2100 - val_loss: 5.0972 - val_mae: 1.2762\n",
      "Epoch 84/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6018 - mae: 1.2107 - val_loss: 5.0959 - val_mae: 1.2689\n",
      "Epoch 85/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.6002 - mae: 1.2082 - val_loss: 5.0954 - val_mae: 1.2862\n",
      "Epoch 86/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5982 - mae: 1.2111 - val_loss: 5.0963 - val_mae: 1.2872\n",
      "Epoch 87/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5970 - mae: 1.2107 - val_loss: 5.0899 - val_mae: 1.2704\n",
      "Epoch 88/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5955 - mae: 1.2108 - val_loss: 5.0895 - val_mae: 1.2637\n",
      "Epoch 89/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5940 - mae: 1.2087 - val_loss: 5.0883 - val_mae: 1.2761\n",
      "Epoch 90/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5927 - mae: 1.2104 - val_loss: 5.0863 - val_mae: 1.2706\n",
      "Epoch 91/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5911 - mae: 1.2080 - val_loss: 5.0876 - val_mae: 1.2886\n",
      "Epoch 92/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5897 - mae: 1.2113 - val_loss: 5.0850 - val_mae: 1.2763\n",
      "Epoch 93/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5885 - mae: 1.2097 - val_loss: 5.0817 - val_mae: 1.2725\n",
      "Epoch 94/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5870 - mae: 1.2086 - val_loss: 5.0819 - val_mae: 1.2820\n",
      "Epoch 95/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5859 - mae: 1.2099 - val_loss: 5.0802 - val_mae: 1.2796\n",
      "Epoch 96/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5842 - mae: 1.2096 - val_loss: 5.0773 - val_mae: 1.2734\n",
      "Epoch 97/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5829 - mae: 1.2092 - val_loss: 5.0769 - val_mae: 1.2810\n",
      "Epoch 98/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5816 - mae: 1.2104 - val_loss: 5.0759 - val_mae: 1.2747\n",
      "Epoch 99/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5803 - mae: 1.2095 - val_loss: 5.0757 - val_mae: 1.2762\n",
      "Epoch 100/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5790 - mae: 1.2092 - val_loss: 5.0726 - val_mae: 1.2725\n",
      "Epoch 101/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5776 - mae: 1.2103 - val_loss: 5.0712 - val_mae: 1.2684\n",
      "Epoch 102/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5763 - mae: 1.2087 - val_loss: 5.0701 - val_mae: 1.2690\n",
      "Epoch 103/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5752 - mae: 1.2086 - val_loss: 5.0699 - val_mae: 1.2775\n",
      "Epoch 104/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5742 - mae: 1.2100 - val_loss: 5.0678 - val_mae: 1.2714\n",
      "Epoch 105/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5732 - mae: 1.2089 - val_loss: 5.0659 - val_mae: 1.2710\n",
      "Epoch 106/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5720 - mae: 1.2089 - val_loss: 5.0653 - val_mae: 1.2714\n",
      "Epoch 107/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5701 - mae: 1.2077 - val_loss: 5.0648 - val_mae: 1.2810\n",
      "Epoch 108/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5691 - mae: 1.2092 - val_loss: 5.0628 - val_mae: 1.2746\n",
      "Epoch 109/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5684 - mae: 1.2092 - val_loss: 5.0617 - val_mae: 1.2720\n",
      "Epoch 110/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5667 - mae: 1.2095 - val_loss: 5.0606 - val_mae: 1.2644\n",
      "Epoch 111/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5662 - mae: 1.2073 - val_loss: 5.0593 - val_mae: 1.2753\n",
      "Epoch 112/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5641 - mae: 1.2087 - val_loss: 5.0605 - val_mae: 1.2746\n",
      "Epoch 113/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5632 - mae: 1.2081 - val_loss: 5.0593 - val_mae: 1.2808\n",
      "Epoch 114/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5621 - mae: 1.2093 - val_loss: 5.0561 - val_mae: 1.2668\n",
      "Epoch 115/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5611 - mae: 1.2071 - val_loss: 5.0552 - val_mae: 1.2805\n",
      "Epoch 116/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5601 - mae: 1.2091 - val_loss: 5.0551 - val_mae: 1.2789\n",
      "Epoch 117/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5587 - mae: 1.2092 - val_loss: 5.0531 - val_mae: 1.2743\n",
      "Epoch 118/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5582 - mae: 1.2079 - val_loss: 5.0533 - val_mae: 1.2780\n",
      "Epoch 119/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5565 - mae: 1.2101 - val_loss: 5.0534 - val_mae: 1.2529\n",
      "Epoch 120/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5564 - mae: 1.2084 - val_loss: 5.0509 - val_mae: 1.2578\n",
      "Epoch 121/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5557 - mae: 1.2079 - val_loss: 5.0500 - val_mae: 1.2598\n",
      "Epoch 122/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5546 - mae: 1.2071 - val_loss: 5.0511 - val_mae: 1.2817\n",
      "Epoch 123/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5543 - mae: 1.2101 - val_loss: 5.0485 - val_mae: 1.2692\n",
      "Epoch 124/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5531 - mae: 1.2068 - val_loss: 5.0483 - val_mae: 1.2815\n",
      "Epoch 125/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5520 - mae: 1.2089 - val_loss: 5.0473 - val_mae: 1.2747\n",
      "Epoch 126/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5519 - mae: 1.2094 - val_loss: 5.0466 - val_mae: 1.2683\n",
      "Epoch 127/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5508 - mae: 1.2080 - val_loss: 5.0458 - val_mae: 1.2719\n",
      "Epoch 128/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5502 - mae: 1.2082 - val_loss: 5.0445 - val_mae: 1.2714\n",
      "Epoch 129/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5495 - mae: 1.2080 - val_loss: 5.0453 - val_mae: 1.2750\n",
      "Epoch 130/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5490 - mae: 1.2087 - val_loss: 5.0442 - val_mae: 1.2721\n",
      "Epoch 131/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5484 - mae: 1.2078 - val_loss: 5.0439 - val_mae: 1.2772\n",
      "Epoch 132/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5477 - mae: 1.2083 - val_loss: 5.0429 - val_mae: 1.27670s - loss: 4.5417 - m\n",
      "Epoch 133/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5469 - mae: 1.2082 - val_loss: 5.0431 - val_mae: 1.2793\n",
      "Epoch 134/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5463 - mae: 1.2085 - val_loss: 5.0415 - val_mae: 1.2690\n",
      "Epoch 135/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5457 - mae: 1.2075 - val_loss: 5.0428 - val_mae: 1.2805\n",
      "Epoch 136/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5452 - mae: 1.2078 - val_loss: 5.0414 - val_mae: 1.2793\n",
      "Epoch 137/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5445 - mae: 1.2086 - val_loss: 5.0399 - val_mae: 1.2713\n",
      "Epoch 138/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5438 - mae: 1.2078 - val_loss: 5.0406 - val_mae: 1.2757\n",
      "Epoch 139/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5430 - mae: 1.2069 - val_loss: 5.0380 - val_mae: 1.2731\n",
      "Epoch 140/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5426 - mae: 1.2084 - val_loss: 5.0390 - val_mae: 1.2747\n",
      "Epoch 141/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5418 - mae: 1.2072 - val_loss: 5.0398 - val_mae: 1.2822\n",
      "Epoch 142/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5417 - mae: 1.2082 - val_loss: 5.0374 - val_mae: 1.2739\n",
      "Epoch 143/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5411 - mae: 1.2085 - val_loss: 5.0361 - val_mae: 1.2610\n",
      "Epoch 144/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5404 - mae: 1.2070 - val_loss: 5.0354 - val_mae: 1.2736\n",
      "Epoch 145/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5398 - mae: 1.2082 - val_loss: 5.0351 - val_mae: 1.2630\n",
      "Epoch 146/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5393 - mae: 1.2074 - val_loss: 5.0352 - val_mae: 1.2755\n",
      "Epoch 147/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5388 - mae: 1.2083 - val_loss: 5.0344 - val_mae: 1.2633\n",
      "Epoch 148/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5385 - mae: 1.2059 - val_loss: 5.0354 - val_mae: 1.2771\n",
      "Epoch 149/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5378 - mae: 1.2073 - val_loss: 5.0336 - val_mae: 1.2756\n",
      "Epoch 150/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5376 - mae: 1.2081 - val_loss: 5.0333 - val_mae: 1.2697\n",
      "Epoch 151/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5369 - mae: 1.2061 - val_loss: 5.0365 - val_mae: 1.2875\n",
      "Epoch 152/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5358 - mae: 1.2078 - val_loss: 5.0371 - val_mae: 1.2814\n",
      "Epoch 153/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5361 - mae: 1.2081 - val_loss: 5.0314 - val_mae: 1.2725\n",
      "Epoch 154/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5349 - mae: 1.2060 - val_loss: 5.0325 - val_mae: 1.2785\n",
      "Epoch 155/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5348 - mae: 1.2080 - val_loss: 5.0305 - val_mae: 1.2730\n",
      "Epoch 156/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5343 - mae: 1.2072 - val_loss: 5.0308 - val_mae: 1.2786\n",
      "Epoch 157/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5339 - mae: 1.2079 - val_loss: 5.0319 - val_mae: 1.2808\n",
      "Epoch 158/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5336 - mae: 1.2073 - val_loss: 5.0307 - val_mae: 1.2746\n",
      "Epoch 159/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5332 - mae: 1.2077 - val_loss: 5.0288 - val_mae: 1.2676\n",
      "Epoch 160/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5322 - mae: 1.2074 - val_loss: 5.0290 - val_mae: 1.2636\n",
      "Epoch 161/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5325 - mae: 1.2069 - val_loss: 5.0280 - val_mae: 1.2713\n",
      "Epoch 162/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5322 - mae: 1.2078 - val_loss: 5.0275 - val_mae: 1.2642\n",
      "Epoch 163/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5315 - mae: 1.2071 - val_loss: 5.0283 - val_mae: 1.2729\n",
      "Epoch 164/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5311 - mae: 1.2072 - val_loss: 5.0267 - val_mae: 1.2642\n",
      "Epoch 165/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5305 - mae: 1.2066 - val_loss: 5.0276 - val_mae: 1.2763\n",
      "Epoch 166/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5298 - mae: 1.2057 - val_loss: 5.0322 - val_mae: 1.2921\n",
      "Epoch 167/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5297 - mae: 1.2081 - val_loss: 5.0274 - val_mae: 1.2819\n",
      "Epoch 168/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5292 - mae: 1.2073 - val_loss: 5.0251 - val_mae: 1.2732\n",
      "Epoch 169/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5289 - mae: 1.2064 - val_loss: 5.0267 - val_mae: 1.2828\n",
      "Epoch 170/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5280 - mae: 1.2080 - val_loss: 5.0248 - val_mae: 1.2686\n",
      "Epoch 171/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5278 - mae: 1.2062 - val_loss: 5.0252 - val_mae: 1.2772\n",
      "Epoch 172/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5277 - mae: 1.2076 - val_loss: 5.0243 - val_mae: 1.2626\n",
      "Epoch 173/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5273 - mae: 1.2067 - val_loss: 5.0244 - val_mae: 1.2718\n",
      "Epoch 174/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5268 - mae: 1.2067 - val_loss: 5.0234 - val_mae: 1.2690\n",
      "Epoch 175/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5262 - mae: 1.2071 - val_loss: 5.0225 - val_mae: 1.2656\n",
      "Epoch 176/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5261 - mae: 1.2055 - val_loss: 5.0233 - val_mae: 1.2824\n",
      "Epoch 177/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5253 - mae: 1.2090 - val_loss: 5.0219 - val_mae: 1.2637\n",
      "Epoch 178/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5249 - mae: 1.2055 - val_loss: 5.0228 - val_mae: 1.2796\n",
      "Epoch 179/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5241 - mae: 1.2073 - val_loss: 5.0210 - val_mae: 1.2712\n",
      "Epoch 180/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5239 - mae: 1.2069 - val_loss: 5.0222 - val_mae: 1.2722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5231 - mae: 1.2059 - val_loss: 5.0234 - val_mae: 1.2809\n",
      "Epoch 182/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5230 - mae: 1.2076 - val_loss: 5.0198 - val_mae: 1.2664\n",
      "Epoch 183/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5224 - mae: 1.2060 - val_loss: 5.0216 - val_mae: 1.2766\n",
      "Epoch 184/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5224 - mae: 1.2067 - val_loss: 5.0194 - val_mae: 1.2728\n",
      "Epoch 185/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5218 - mae: 1.2070 - val_loss: 5.0187 - val_mae: 1.2691\n",
      "Epoch 186/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5213 - mae: 1.2062 - val_loss: 5.0192 - val_mae: 1.2769\n",
      "Epoch 187/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5211 - mae: 1.2078 - val_loss: 5.0182 - val_mae: 1.2634\n",
      "Epoch 188/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5209 - mae: 1.2059 - val_loss: 5.0175 - val_mae: 1.2701\n",
      "Epoch 189/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5205 - mae: 1.2070 - val_loss: 5.0175 - val_mae: 1.2648\n",
      "Epoch 190/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5200 - mae: 1.2058 - val_loss: 5.0175 - val_mae: 1.2724\n",
      "Epoch 191/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5197 - mae: 1.2051 - val_loss: 5.0197 - val_mae: 1.2858\n",
      "Epoch 192/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5193 - mae: 1.2072 - val_loss: 5.0180 - val_mae: 1.2769\n",
      "Epoch 193/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5192 - mae: 1.2066 - val_loss: 5.0168 - val_mae: 1.2747\n",
      "Epoch 194/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5180 - mae: 1.2059 - val_loss: 5.0159 - val_mae: 1.2715 \n",
      "Epoch 195/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5181 - mae: 1.2063 - val_loss: 5.0150 - val_mae: 1.2695\n",
      "Epoch 196/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5181 - mae: 1.2059 - val_loss: 5.0153 - val_mae: 1.2744\n",
      "Epoch 197/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5176 - mae: 1.2068 - val_loss: 5.0159 - val_mae: 1.2727\n",
      "Epoch 198/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5169 - mae: 1.2057 - val_loss: 5.0191 - val_mae: 1.2834\n",
      "Epoch 199/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5170 - mae: 1.2061 - val_loss: 5.0158 - val_mae: 1.2800\n",
      "Epoch 200/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5162 - mae: 1.2068 - val_loss: 5.0143 - val_mae: 1.2689\n",
      "Epoch 201/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5158 - mae: 1.2049 - val_loss: 5.0166 - val_mae: 1.2813\n",
      "Epoch 202/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5160 - mae: 1.2063 - val_loss: 5.0134 - val_mae: 1.2728\n",
      "Epoch 203/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5152 - mae: 1.2063 - val_loss: 5.0136 - val_mae: 1.2758\n",
      "Epoch 204/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5147 - mae: 1.2058 - val_loss: 5.0135 - val_mae: 1.2776\n",
      "Epoch 205/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5145 - mae: 1.2064 - val_loss: 5.0126 - val_mae: 1.2720\n",
      "Epoch 206/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5140 - mae: 1.2055 - val_loss: 5.0124 - val_mae: 1.2731\n",
      "Epoch 207/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5139 - mae: 1.2068 - val_loss: 5.0128 - val_mae: 1.2704\n",
      "Epoch 208/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5131 - mae: 1.2052 - val_loss: 5.0121 - val_mae: 1.2746\n",
      "Epoch 209/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5133 - mae: 1.2057 - val_loss: 5.0126 - val_mae: 1.2749\n",
      "Epoch 210/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5126 - mae: 1.2066 - val_loss: 5.0109 - val_mae: 1.2622\n",
      "Epoch 211/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5123 - mae: 1.2044 - val_loss: 5.0103 - val_mae: 1.2721\n",
      "Epoch 212/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5115 - mae: 1.2061 - val_loss: 5.0109 - val_mae: 1.2697\n",
      "Epoch 213/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5116 - mae: 1.2060 - val_loss: 5.0100 - val_mae: 1.2695\n",
      "Epoch 214/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5114 - mae: 1.2052 - val_loss: 5.0106 - val_mae: 1.2724\n",
      "Epoch 215/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5111 - mae: 1.2064 - val_loss: 5.0092 - val_mae: 1.2639\n",
      "Epoch 216/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5110 - mae: 1.2061 - val_loss: 5.0089 - val_mae: 1.2615\n",
      "Epoch 217/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5105 - mae: 1.2047 - val_loss: 5.0094 - val_mae: 1.2672oss: 4.4950 - mae: 1\n",
      "Epoch 218/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5101 - mae: 1.2057 - val_loss: 5.0080 - val_mae: 1.2681TA:\n",
      "Epoch 219/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5099 - mae: 1.2047 - val_loss: 5.0079 - val_mae: 1.2731\n",
      "Epoch 220/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5096 - mae: 1.2059 - val_loss: 5.0078 - val_mae: 1.2681\n",
      "Epoch 221/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5091 - mae: 1.2055 - val_loss: 5.0070 - val_mae: 1.2659\n",
      "Epoch 222/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5087 - mae: 1.2054 - val_loss: 5.0067 - val_mae: 1.2624\n",
      "Epoch 223/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5085 - mae: 1.2055 - val_loss: 5.0069 - val_mae: 1.2675\n",
      "Epoch 224/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5078 - mae: 1.2040 - val_loss: 5.0068 - val_mae: 1.2777\n",
      "Epoch 225/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5076 - mae: 1.2069 - val_loss: 5.0066 - val_mae: 1.2654\n",
      "Epoch 226/300\n",
      "2276/2276 [==============================] - 4s 2ms/step - loss: 4.5068 - mae: 1.2045 - val_loss: 5.0083 - val_mae: 1.2753\n",
      "Epoch 227/300\n",
      "2276/2276 [==============================] - 4s 2ms/step - loss: 4.5066 - mae: 1.2048 - val_loss: 5.0049 - val_mae: 1.2700\n",
      "Epoch 228/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5059 - mae: 1.2050 - val_loss: 5.0056 - val_mae: 1.2715\n",
      "Epoch 229/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5061 - mae: 1.2044 - val_loss: 5.0051 - val_mae: 1.2809\n",
      "Epoch 230/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5057 - mae: 1.2065 - val_loss: 5.0037 - val_mae: 1.2662\n",
      "Epoch 231/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5048 - mae: 1.2045 - val_loss: 5.0036 - val_mae: 1.2695\n",
      "Epoch 232/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5046 - mae: 1.2049 - val_loss: 5.0049 - val_mae: 1.2772s - \n",
      "Epoch 233/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5040 - mae: 1.2062 - val_loss: 5.0030 - val_mae: 1.2615\n",
      "Epoch 234/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5042 - mae: 1.2041 - val_loss: 5.0039 - val_mae: 1.2765\n",
      "Epoch 235/300\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5036 - mae: 1.2049 - val_loss: 5.0026 - val_mae: 1.2720\n",
      "Epoch 236/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5034 - mae: 1.2058 - val_loss: 5.0022 - val_mae: 1.2649\n",
      "Epoch 237/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5029 - mae: 1.2042 - val_loss: 5.0017 - val_mae: 1.2713\n",
      "Epoch 238/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5025 - mae: 1.2044 - val_loss: 5.0035 - val_mae: 1.2794\n",
      "Epoch 239/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5021 - mae: 1.2051 - val_loss: 5.0013 - val_mae: 1.2689\n",
      "Epoch 240/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5016 - mae: 1.2043 - val_loss: 5.0013 - val_mae: 1.2670\n",
      "Epoch 241/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5013 - mae: 1.2049 - val_loss: 5.0016 - val_mae: 1.2705\n",
      "Epoch 242/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5007 - mae: 1.2047 - val_loss: 5.0002 - val_mae: 1.2612\n",
      "Epoch 243/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5003 - mae: 1.2051 - val_loss: 5.0003 - val_mae: 1.2614\n",
      "Epoch 244/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5001 - mae: 1.2030 - val_loss: 5.0017 - val_mae: 1.2791\n",
      "Epoch 245/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4997 - mae: 1.2054 - val_loss: 5.0001 - val_mae: 1.2741\n",
      "Epoch 246/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4995 - mae: 1.2041 - val_loss: 4.9990 - val_mae: 1.2696\n",
      "Epoch 247/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4983 - mae: 1.2035 - val_loss: 5.0048 - val_mae: 1.2882\n",
      "Epoch 248/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4989 - mae: 1.2063 - val_loss: 4.9998 - val_mae: 1.2649\n",
      "Epoch 249/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4982 - mae: 1.2030 - val_loss: 4.9999 - val_mae: 1.2766\n",
      "Epoch 250/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4981 - mae: 1.2053 - val_loss: 4.9991 - val_mae: 1.2651\n",
      "Epoch 251/300\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4973 - mae: 1.2039 - val_loss: 4.9993 - val_mae: 1.2704\n"
     ]
    }
   ],
   "source": [
    "model = init_model(27,learn = 0.00003)\n",
    "es = EarlyStopping(patience=5)\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train, \n",
    "                  batch_size=32, \n",
    "                  epochs=300, \n",
    "                  validation_split=0.3,\n",
    "                  callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc123182",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 781us/step - loss: 4.1593 - mae: 1.0943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.15932559967041, 1.094316005706787]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_eval = model.evaluate(X_test_scaled, y_test)\n",
    "y_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f61cca0",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Score = 1.065389  ---- layers: 35, 20, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21eb9faa",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of positions = 4\n",
      "Index(['r_assists', 'r_bonus', 'r_bps', 'r_clean_sheets', 'r_creativity',\n",
      "       'r_goals_conceded', 'r_threat', 'r_goals_scored', 'r_ict_index',\n",
      "       'r_influence', 'r_minutes', 'r_own_goals', 'r_penalties_missed',\n",
      "       'r_penalties_saved', 'r_red_cards', 'r_saves', 'r_transfers_balance',\n",
      "       'r_value', 'r_yellow_cards', 'r_team_a_score', 'r_team_h_score',\n",
      "       'r_total_points', 'was_home', 'DEF', 'FWD', 'GK', 'MID'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(104005, 27)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop = [\"name\",\"level_1\",\"season\",\"position\",\"GW\"]\n",
    "roll = 2\n",
    "\n",
    "X_train_scaled, X_test_scaled, y_train, y_test = model_ready(full_data, drop, roll)\n",
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a18dba8e",
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "2276/2276 [==============================] - 4s 1ms/step - loss: 7.3337 - mae: 1.2654 - val_loss: 6.6380 - val_mae: 1.3004\n",
      "Epoch 2/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 5.8585 - mae: 1.2595 - val_loss: 6.2198 - val_mae: 1.3184\n",
      "Epoch 3/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 5.6162 - mae: 1.2459 - val_loss: 6.0306 - val_mae: 1.2955\n",
      "Epoch 4/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 5.4815 - mae: 1.2312 - val_loss: 5.9171 - val_mae: 1.2988\n",
      "Epoch 5/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 5.3890 - mae: 1.2299 - val_loss: 5.8342 - val_mae: 1.2784\n",
      "Epoch 6/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 5.3160 - mae: 1.2213 - val_loss: 5.7666 - val_mae: 1.2894\n",
      "Epoch 7/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 5.2538 - mae: 1.2220 - val_loss: 5.7100 - val_mae: 1.2802\n",
      "Epoch 8/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 5.2020 - mae: 1.2186 - val_loss: 5.6614 - val_mae: 1.2854\n",
      "Epoch 9/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 5.1560 - mae: 1.2198 - val_loss: 5.6194 - val_mae: 1.2804\n",
      "Epoch 10/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 5.1153 - mae: 1.2186 - val_loss: 5.5817 - val_mae: 1.2831\n",
      "Epoch 11/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 5.0786 - mae: 1.2189 - val_loss: 5.5477 - val_mae: 1.2792\n",
      "Epoch 12/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 5.0463 - mae: 1.2174 - val_loss: 5.5185 - val_mae: 1.2766\n",
      "Epoch 13/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 5.0171 - mae: 1.2155 - val_loss: 5.4926 - val_mae: 1.2854\n",
      "Epoch 14/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.9910 - mae: 1.2174 - val_loss: 5.4681 - val_mae: 1.2758\n",
      "Epoch 15/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.9669 - mae: 1.2162 - val_loss: 5.4472 - val_mae: 1.2744\n",
      "Epoch 16/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.9450 - mae: 1.2134 - val_loss: 5.4281 - val_mae: 1.2884\n",
      "Epoch 17/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.9247 - mae: 1.2155 - val_loss: 5.4060 - val_mae: 1.2763\n",
      "Epoch 18/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.9051 - mae: 1.2141 - val_loss: 5.3890 - val_mae: 1.2665\n",
      "Epoch 19/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.8876 - mae: 1.2110 - val_loss: 5.3714 - val_mae: 1.2817\n",
      "Epoch 20/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.8704 - mae: 1.2125 - val_loss: 5.3541 - val_mae: 1.2840\n",
      "Epoch 21/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.8554 - mae: 1.2129 - val_loss: 5.3396 - val_mae: 1.2793\n",
      "Epoch 22/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.8407 - mae: 1.2130 - val_loss: 5.3270 - val_mae: 1.2776\n",
      "Epoch 23/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.8267 - mae: 1.2113 - val_loss: 5.3127 - val_mae: 1.2845\n",
      "Epoch 24/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.8133 - mae: 1.2140 - val_loss: 5.3008 - val_mae: 1.2718\n",
      "Epoch 25/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.8007 - mae: 1.2119 - val_loss: 5.2883 - val_mae: 1.2740\n",
      "Epoch 26/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.7895 - mae: 1.2115 - val_loss: 5.2771 - val_mae: 1.2750\n",
      "Epoch 27/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.7777 - mae: 1.2122 - val_loss: 5.2654 - val_mae: 1.2779\n",
      "Epoch 28/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.7674 - mae: 1.2131 - val_loss: 5.2551 - val_mae: 1.2764\n",
      "Epoch 29/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.7576 - mae: 1.2115 - val_loss: 5.2475 - val_mae: 1.2841\n",
      "Epoch 30/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.7479 - mae: 1.2129 - val_loss: 5.2382 - val_mae: 1.2730\n",
      "Epoch 31/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.7394 - mae: 1.2114 - val_loss: 5.2298 - val_mae: 1.2782\n",
      "Epoch 32/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.7310 - mae: 1.2127 - val_loss: 5.2211 - val_mae: 1.2718\n",
      "Epoch 33/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.7230 - mae: 1.2118 - val_loss: 5.2133 - val_mae: 1.2662\n",
      "Epoch 34/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.7155 - mae: 1.2104 - val_loss: 5.2074 - val_mae: 1.2755\n",
      "Epoch 35/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.7087 - mae: 1.2108 - val_loss: 5.1994 - val_mae: 1.2843\n",
      "Epoch 36/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.7019 - mae: 1.2115 - val_loss: 5.1946 - val_mae: 1.2800\n",
      "Epoch 37/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6956 - mae: 1.2111 - val_loss: 5.1858 - val_mae: 1.2742\n",
      "Epoch 38/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6885 - mae: 1.2099 - val_loss: 5.1812 - val_mae: 1.2859\n",
      "Epoch 39/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6827 - mae: 1.2121 - val_loss: 5.1740 - val_mae: 1.2712\n",
      "Epoch 40/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.6772 - mae: 1.2101 - val_loss: 5.1692 - val_mae: 1.2850\n",
      "Epoch 41/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6718 - mae: 1.2126 - val_loss: 5.1635 - val_mae: 1.2627\n",
      "Epoch 42/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6664 - mae: 1.2110 - val_loss: 5.1595 - val_mae: 1.2610\n",
      "Epoch 43/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.6612 - mae: 1.2087 - val_loss: 5.1547 - val_mae: 1.2814\n",
      "Epoch 44/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6562 - mae: 1.2110 - val_loss: 5.1489 - val_mae: 1.2640\n",
      "Epoch 45/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6519 - mae: 1.2097 - val_loss: 5.1441 - val_mae: 1.2703\n",
      "Epoch 46/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.6474 - mae: 1.2089 - val_loss: 5.1399 - val_mae: 1.2751\n",
      "Epoch 47/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6429 - mae: 1.2088 - val_loss: 5.1360 - val_mae: 1.2750\n",
      "Epoch 48/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6381 - mae: 1.2097 - val_loss: 5.1367 - val_mae: 1.2826\n",
      "Epoch 49/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6346 - mae: 1.2108 - val_loss: 5.1293 - val_mae: 1.2738\n",
      "Epoch 50/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6302 - mae: 1.2094 - val_loss: 5.1266 - val_mae: 1.2711\n",
      "Epoch 51/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6271 - mae: 1.2091 - val_loss: 5.1206 - val_mae: 1.2731\n",
      "Epoch 52/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.6231 - mae: 1.2094 - val_loss: 5.1168 - val_mae: 1.2694\n",
      "Epoch 53/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6195 - mae: 1.2093 - val_loss: 5.1143 - val_mae: 1.2724\n",
      "Epoch 54/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6163 - mae: 1.2092 - val_loss: 5.1108 - val_mae: 1.2679\n",
      "Epoch 55/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6124 - mae: 1.2090 - val_loss: 5.1103 - val_mae: 1.2828\n",
      "Epoch 56/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6092 - mae: 1.2105 - val_loss: 5.1061 - val_mae: 1.2692\n",
      "Epoch 57/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6067 - mae: 1.2069 - val_loss: 5.1068 - val_mae: 1.2950\n",
      "Epoch 58/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6039 - mae: 1.2110 - val_loss: 5.0997 - val_mae: 1.2708\n",
      "Epoch 59/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6004 - mae: 1.2087 - val_loss: 5.0965 - val_mae: 1.2751\n",
      "Epoch 60/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5980 - mae: 1.2099 - val_loss: 5.0938 - val_mae: 1.2654\n",
      "Epoch 61/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5950 - mae: 1.2080 - val_loss: 5.0911 - val_mae: 1.2663\n",
      "Epoch 62/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5927 - mae: 1.2091 - val_loss: 5.0887 - val_mae: 1.2778\n",
      "Epoch 63/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5894 - mae: 1.2098 - val_loss: 5.0865 - val_mae: 1.2659\n",
      "Epoch 64/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5865 - mae: 1.2073 - val_loss: 5.0893 - val_mae: 1.2818\n",
      "Epoch 65/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5844 - mae: 1.2098 - val_loss: 5.0819 - val_mae: 1.2656\n",
      "Epoch 66/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5824 - mae: 1.2081 - val_loss: 5.0792 - val_mae: 1.2679\n",
      "Epoch 67/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5792 - mae: 1.2089 - val_loss: 5.0772 - val_mae: 1.2686\n",
      "Epoch 68/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5770 - mae: 1.2086 - val_loss: 5.0754 - val_mae: 1.2743\n",
      "Epoch 69/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5748 - mae: 1.2080 - val_loss: 5.0751 - val_mae: 1.2833\n",
      "Epoch 70/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5729 - mae: 1.2088 - val_loss: 5.0710 - val_mae: 1.2789\n",
      "Epoch 71/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5706 - mae: 1.2077 - val_loss: 5.0708 - val_mae: 1.2874\n",
      "Epoch 72/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5682 - mae: 1.2084 - val_loss: 5.0693 - val_mae: 1.2854\n",
      "Epoch 73/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5666 - mae: 1.2091 - val_loss: 5.0648 - val_mae: 1.2751\n",
      "Epoch 74/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5645 - mae: 1.2082 - val_loss: 5.0634 - val_mae: 1.2756\n",
      "Epoch 75/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5623 - mae: 1.2081 - val_loss: 5.0613 - val_mae: 1.2728\n",
      "Epoch 76/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5606 - mae: 1.2069 - val_loss: 5.0621 - val_mae: 1.2913\n",
      "Epoch 77/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5587 - mae: 1.2089 - val_loss: 5.0574 - val_mae: 1.2754\n",
      "Epoch 78/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5572 - mae: 1.2076 - val_loss: 5.0580 - val_mae: 1.2830\n",
      "Epoch 79/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5551 - mae: 1.2076 - val_loss: 5.0558 - val_mae: 1.2808\n",
      "Epoch 80/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5538 - mae: 1.2087 - val_loss: 5.0526 - val_mae: 1.2698\n",
      "Epoch 81/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5517 - mae: 1.2070 - val_loss: 5.0510 - val_mae: 1.2804\n",
      "Epoch 82/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5500 - mae: 1.2088 - val_loss: 5.0501 - val_mae: 1.2620\n",
      "Epoch 83/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5484 - mae: 1.2072 - val_loss: 5.0479 - val_mae: 1.2668\n",
      "Epoch 84/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5468 - mae: 1.2066 - val_loss: 5.0467 - val_mae: 1.2764\n",
      "Epoch 85/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5446 - mae: 1.2067 - val_loss: 5.0488 - val_mae: 1.2890\n",
      "Epoch 86/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5434 - mae: 1.2084 - val_loss: 5.0446 - val_mae: 1.2750\n",
      "Epoch 87/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5414 - mae: 1.2058 - val_loss: 5.0473 - val_mae: 1.2894\n",
      "Epoch 88/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5408 - mae: 1.2087 - val_loss: 5.0410 - val_mae: 1.2646\n",
      "Epoch 89/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5389 - mae: 1.2066 - val_loss: 5.0399 - val_mae: 1.2677\n",
      "Epoch 90/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5377 - mae: 1.2075 - val_loss: 5.0387 - val_mae: 1.2607\n",
      "Epoch 91/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5356 - mae: 1.2060 - val_loss: 5.0395 - val_mae: 1.2684\n",
      "Epoch 92/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5347 - mae: 1.2062 - val_loss: 5.0360 - val_mae: 1.2819\n",
      "Epoch 93/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5328 - mae: 1.2077 - val_loss: 5.0341 - val_mae: 1.2651\n",
      "Epoch 94/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5321 - mae: 1.2061 - val_loss: 5.0339 - val_mae: 1.2715\n",
      "Epoch 95/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5306 - mae: 1.2061 - val_loss: 5.0352 - val_mae: 1.2798\n",
      "Epoch 96/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5301 - mae: 1.2074 - val_loss: 5.0313 - val_mae: 1.2743\n",
      "Epoch 97/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5284 - mae: 1.2058 - val_loss: 5.0306 - val_mae: 1.2692\n",
      "Epoch 98/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5276 - mae: 1.2053 - val_loss: 5.0322 - val_mae: 1.2867\n",
      "Epoch 99/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5259 - mae: 1.2065 - val_loss: 5.0305 - val_mae: 1.275631 - mae:\n",
      "Epoch 100/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5249 - mae: 1.2063 - val_loss: 5.0276 - val_mae: 1.2672\n",
      "Epoch 101/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5239 - mae: 1.2050 - val_loss: 5.0272 - val_mae: 1.2811\n",
      "Epoch 102/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5229 - mae: 1.2067 - val_loss: 5.0266 - val_mae: 1.2754\n",
      "Epoch 103/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5213 - mae: 1.2073 - val_loss: 5.0265 - val_mae: 1.2516\n",
      "Epoch 104/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5211 - mae: 1.2034 - val_loss: 5.0247 - val_mae: 1.2793\n",
      "Epoch 105/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5195 - mae: 1.2055 - val_loss: 5.0220 - val_mae: 1.2791\n",
      "Epoch 106/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5191 - mae: 1.2064 - val_loss: 5.0224 - val_mae: 1.2784\n",
      "Epoch 107/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5178 - mae: 1.2060 - val_loss: 5.0212 - val_mae: 1.2655\n",
      "Epoch 108/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5172 - mae: 1.2049 - val_loss: 5.0222 - val_mae: 1.2770\n",
      "Epoch 109/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5161 - mae: 1.2066 - val_loss: 5.0189 - val_mae: 1.2673\n",
      "Epoch 110/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5148 - mae: 1.2045 - val_loss: 5.0184 - val_mae: 1.2768\n",
      "Epoch 111/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5144 - mae: 1.2043 - val_loss: 5.0181 - val_mae: 1.2815\n",
      "Epoch 112/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5134 - mae: 1.2054 - val_loss: 5.0167 - val_mae: 1.2741\n",
      "Epoch 113/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5122 - mae: 1.2056 - val_loss: 5.0152 - val_mae: 1.2661\n",
      "Epoch 114/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5116 - mae: 1.2049 - val_loss: 5.0145 - val_mae: 1.2733\n",
      "Epoch 115/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5103 - mae: 1.2043 - val_loss: 5.0183 - val_mae: 1.2833\n",
      "Epoch 116/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5096 - mae: 1.2063 - val_loss: 5.0129 - val_mae: 1.2597\n",
      "Epoch 117/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5086 - mae: 1.2046 - val_loss: 5.0123 - val_mae: 1.2690\n",
      "Epoch 118/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5075 - mae: 1.2035 - val_loss: 5.0139 - val_mae: 1.2863\n",
      "Epoch 119/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5072 - mae: 1.2052 - val_loss: 5.0125 - val_mae: 1.2856\n",
      "Epoch 120/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5063 - mae: 1.2052 - val_loss: 5.0098 - val_mae: 1.2610\n",
      "Epoch 121/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5052 - mae: 1.2045 - val_loss: 5.0092 - val_mae: 1.2635\n",
      "Epoch 122/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5042 - mae: 1.2038 - val_loss: 5.0080 - val_mae: 1.2671\n",
      "Epoch 123/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5037 - mae: 1.2048 - val_loss: 5.0074 - val_mae: 1.2631\n",
      "Epoch 124/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5028 - mae: 1.2040 - val_loss: 5.0111 - val_mae: 1.2798\n",
      "Epoch 125/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5024 - mae: 1.2045 - val_loss: 5.0063 - val_mae: 1.2761\n",
      "Epoch 126/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5013 - mae: 1.2047 - val_loss: 5.0056 - val_mae: 1.2643\n",
      "Epoch 127/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5005 - mae: 1.2040 - val_loss: 5.0051 - val_mae: 1.2709\n",
      "Epoch 128/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5000 - mae: 1.2044 - val_loss: 5.0060 - val_mae: 1.2687\n",
      "Epoch 129/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4994 - mae: 1.2041 - val_loss: 5.0043 - val_mae: 1.2598\n",
      "Epoch 130/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4986 - mae: 1.2026 - val_loss: 5.0032 - val_mae: 1.2727\n",
      "Epoch 131/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4978 - mae: 1.2047 - val_loss: 5.0020 - val_mae: 1.2661\n",
      "Epoch 132/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4971 - mae: 1.2022 - val_loss: 5.0068 - val_mae: 1.2936\n",
      "Epoch 133/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4967 - mae: 1.2051 - val_loss: 5.0014 - val_mae: 1.2688\n",
      "Epoch 134/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4957 - mae: 1.2029 - val_loss: 5.0028 - val_mae: 1.2689\n",
      "Epoch 135/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4953 - mae: 1.2042 - val_loss: 5.0001 - val_mae: 1.2695\n",
      "Epoch 136/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4944 - mae: 1.2041 - val_loss: 4.9996 - val_mae: 1.2693\n",
      "Epoch 137/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4937 - mae: 1.2030 - val_loss: 5.0017 - val_mae: 1.2739\n",
      "Epoch 138/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4936 - mae: 1.2027 - val_loss: 5.0009 - val_mae: 1.2793\n",
      "Epoch 139/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4926 - mae: 1.2052 - val_loss: 4.9986 - val_mae: 1.2554\n",
      "Epoch 140/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4926 - mae: 1.2024 - val_loss: 4.9983 - val_mae: 1.2758\n",
      "Epoch 141/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4915 - mae: 1.2038 - val_loss: 4.9969 - val_mae: 1.2738\n",
      "Epoch 142/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4910 - mae: 1.2027 - val_loss: 4.9962 - val_mae: 1.2727\n",
      "Epoch 143/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4907 - mae: 1.2033 - val_loss: 4.9982 - val_mae: 1.2745\n",
      "Epoch 144/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4900 - mae: 1.2033 - val_loss: 4.9970 - val_mae: 1.2657\n",
      "Epoch 145/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4890 - mae: 1.2018 - val_loss: 5.0004 - val_mae: 1.2873\n",
      "Epoch 146/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4885 - mae: 1.2038 - val_loss: 4.9951 - val_mae: 1.2593\n",
      "Epoch 147/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4882 - mae: 1.2024 - val_loss: 4.9953 - val_mae: 1.2656\n",
      "Epoch 148/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4876 - mae: 1.2017 - val_loss: 4.9982 - val_mae: 1.2907\n",
      "Epoch 149/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4869 - mae: 1.2045 - val_loss: 4.9936 - val_mae: 1.2681\n",
      "Epoch 150/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4867 - mae: 1.2028 - val_loss: 4.9928 - val_mae: 1.2656 - loss: 4.4877 - mae: 1.2\n",
      "Epoch 151/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4857 - mae: 1.2028 - val_loss: 4.9926 - val_mae: 1.2609\n",
      "Epoch 152/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4854 - mae: 1.2022 - val_loss: 4.9948 - val_mae: 1.2756\n",
      "Epoch 153/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4848 - mae: 1.2031 - val_loss: 4.9934 - val_mae: 1.2644\n",
      "Epoch 154/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4850 - mae: 1.2026 - val_loss: 4.9931 - val_mae: 1.2718\n",
      "Epoch 155/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4842 - mae: 1.2031 - val_loss: 4.9917 - val_mae: 1.2533\n",
      "Epoch 156/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4838 - mae: 1.2022 - val_loss: 4.9901 - val_mae: 1.2631\n",
      "Epoch 157/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4818 - mae: 1.2023 - val_loss: 4.9949 - val_mae: 1.2797\n",
      "Epoch 158/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4826 - mae: 1.2033 - val_loss: 4.9904 - val_mae: 1.2531\n",
      "Epoch 159/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4822 - mae: 1.2035 - val_loss: 4.9905 - val_mae: 1.2598\n",
      "Epoch 160/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4816 - mae: 1.2012 - val_loss: 4.9887 - val_mae: 1.2704\n",
      "Epoch 161/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4813 - mae: 1.2039 - val_loss: 4.9893 - val_mae: 1.2679\n",
      "Epoch 162/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4813 - mae: 1.2022 - val_loss: 4.9893 - val_mae: 1.2687\n",
      "Epoch 163/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4800 - mae: 1.2019 - val_loss: 4.9907 - val_mae: 1.2737\n",
      "Epoch 164/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4797 - mae: 1.2024 - val_loss: 4.9901 - val_mae: 1.2841\n",
      "Epoch 165/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4794 - mae: 1.2015 - val_loss: 4.9874 - val_mae: 1.2687\n",
      "Epoch 166/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4785 - mae: 1.2022 - val_loss: 4.9865 - val_mae: 1.2692\n",
      "Epoch 167/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4782 - mae: 1.2025 - val_loss: 4.9875 - val_mae: 1.2730\n",
      "Epoch 168/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4776 - mae: 1.2018 - val_loss: 4.9876 - val_mae: 1.2650\n",
      "Epoch 169/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4778 - mae: 1.2031 - val_loss: 4.9870 - val_mae: 1.2584\n",
      "Epoch 170/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4774 - mae: 1.2019 - val_loss: 4.9872 - val_mae: 1.2588\n",
      "Epoch 171/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4764 - mae: 1.2023 - val_loss: 4.9898 - val_mae: 1.2422\n"
     ]
    }
   ],
   "source": [
    "model = init_model(27,learn = 0.00003)\n",
    "es = EarlyStopping(patience=5)\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train, \n",
    "                  batch_size=32, \n",
    "                  epochs=400, \n",
    "                  validation_split=0.3,\n",
    "                  callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8cbfe58",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 753us/step - loss: 4.1466 - mae: 1.0654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.146623611450195, 1.0653893947601318]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_eval = model.evaluate(X_test_scaled, y_test)\n",
    "y_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd026c35",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Score = 1.09218 ------- layers: 35, 17, 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "907ab815",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of positions = 4\n",
      "Index(['r_assists', 'r_bonus', 'r_bps', 'r_clean_sheets', 'r_creativity',\n",
      "       'r_goals_conceded', 'r_threat', 'r_goals_scored', 'r_ict_index',\n",
      "       'r_influence', 'r_minutes', 'r_own_goals', 'r_penalties_missed',\n",
      "       'r_penalties_saved', 'r_red_cards', 'r_saves', 'r_transfers_balance',\n",
      "       'r_value', 'r_yellow_cards', 'r_team_a_score', 'r_team_h_score',\n",
      "       'r_total_points', 'was_home', 'DEF', 'FWD', 'GK', 'MID'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(104005, 27)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop = [\"name\",\"level_1\",\"season\",\"position\",\"GW\"]\n",
    "roll = 2\n",
    "\n",
    "X_train_scaled, X_test_scaled, y_train, y_test = model_ready(full_data, drop, roll)\n",
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "26daf90e",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 6.4316 - mae: 1.2634 - val_loss: 6.4211 - val_mae: 1.3219\n",
      "Epoch 2/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 5.7339 - mae: 1.2656 - val_loss: 6.1559 - val_mae: 1.3154\n",
      "Epoch 3/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 5.5673 - mae: 1.2568 - val_loss: 6.0089 - val_mae: 1.3080\n",
      "Epoch 4/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 5.4607 - mae: 1.2534 - val_loss: 5.9094 - val_mae: 1.2984\n",
      "Epoch 5/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 5.3800 - mae: 1.2463 - val_loss: 5.8316 - val_mae: 1.3017\n",
      "Epoch 6/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 5.3125 - mae: 1.2407 - val_loss: 5.7670 - val_mae: 1.2979\n",
      "Epoch 7/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 5.2557 - mae: 1.2346 - val_loss: 5.7146 - val_mae: 1.2966\n",
      "Epoch 8/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 5.2059 - mae: 1.2313 - val_loss: 5.6697 - val_mae: 1.2973\n",
      "Epoch 9/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 5.1632 - mae: 1.2296 - val_loss: 5.6276 - val_mae: 1.2789\n",
      "Epoch 10/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 5.1246 - mae: 1.2215 - val_loss: 5.5956 - val_mae: 1.2923\n",
      "Epoch 11/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 5.0910 - mae: 1.2226 - val_loss: 5.5595 - val_mae: 1.2827\n",
      "Epoch 12/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 5.0598 - mae: 1.2196 - val_loss: 5.5331 - val_mae: 1.2886\n",
      "Epoch 13/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 5.0324 - mae: 1.2196 - val_loss: 5.5038 - val_mae: 1.2794\n",
      "Epoch 14/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 5.0059 - mae: 1.2171 - val_loss: 5.4835 - val_mae: 1.2933\n",
      "Epoch 15/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.9820 - mae: 1.2199 - val_loss: 5.4561 - val_mae: 1.2755\n",
      "Epoch 16/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.9587 - mae: 1.2146 - val_loss: 5.4363 - val_mae: 1.2847- loss: 4.9447 - mae\n",
      "Epoch 17/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.9371 - mae: 1.2168 - val_loss: 5.4129 - val_mae: 1.2724\n",
      "Epoch 18/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.9182 - mae: 1.2154 - val_loss: 5.3963 - val_mae: 1.2781\n",
      "Epoch 19/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.9007 - mae: 1.2141 - val_loss: 5.3787 - val_mae: 1.2770\n",
      "Epoch 20/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.8836 - mae: 1.2139 - val_loss: 5.3657 - val_mae: 1.2832\n",
      "Epoch 21/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.8682 - mae: 1.2135 - val_loss: 5.3504 - val_mae: 1.2841\n",
      "Epoch 22/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.8535 - mae: 1.2144 - val_loss: 5.3368 - val_mae: 1.2826\n",
      "Epoch 23/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.8400 - mae: 1.2138 - val_loss: 5.3237 - val_mae: 1.2772\n",
      "Epoch 24/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.8275 - mae: 1.2133 - val_loss: 5.3119 - val_mae: 1.2793\n",
      "Epoch 25/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.8152 - mae: 1.2131 - val_loss: 5.3016 - val_mae: 1.2823\n",
      "Epoch 26/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.8040 - mae: 1.2143 - val_loss: 5.2907 - val_mae: 1.2745\n",
      "Epoch 27/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.7934 - mae: 1.2128 - val_loss: 5.2803 - val_mae: 1.2737\n",
      "Epoch 28/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.7836 - mae: 1.2121 - val_loss: 5.2710 - val_mae: 1.2772\n",
      "Epoch 29/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.7739 - mae: 1.2116 - val_loss: 5.2625 - val_mae: 1.2850\n",
      "Epoch 30/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.7649 - mae: 1.2132 - val_loss: 5.2533 - val_mae: 1.2804\n",
      "Epoch 31/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.7562 - mae: 1.2128 - val_loss: 5.2449 - val_mae: 1.2793\n",
      "Epoch 32/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.7478 - mae: 1.2121 - val_loss: 5.2369 - val_mae: 1.2788\n",
      "Epoch 33/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.7399 - mae: 1.2120 - val_loss: 5.2315 - val_mae: 1.2826\n",
      "Epoch 34/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.7319 - mae: 1.2111 - val_loss: 5.2227 - val_mae: 1.2856\n",
      "Epoch 35/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.7246 - mae: 1.2127 - val_loss: 5.2147 - val_mae: 1.2753\n",
      "Epoch 36/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.7174 - mae: 1.2114 - val_loss: 5.2100 - val_mae: 1.2795\n",
      "Epoch 37/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.7109 - mae: 1.2118 - val_loss: 5.2025 - val_mae: 1.2722\n",
      "Epoch 38/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.7042 - mae: 1.2107 - val_loss: 5.1978 - val_mae: 1.2801\n",
      "Epoch 39/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6980 - mae: 1.2113 - val_loss: 5.1904 - val_mae: 1.2781\n",
      "Epoch 40/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.6925 - mae: 1.2115 - val_loss: 5.1855 - val_mae: 1.2762\n",
      "Epoch 41/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6867 - mae: 1.2102 - val_loss: 5.1830 - val_mae: 1.2829\n",
      "Epoch 42/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6817 - mae: 1.2115 - val_loss: 5.1751 - val_mae: 1.2732\n",
      "Epoch 43/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6766 - mae: 1.2102 - val_loss: 5.1721 - val_mae: 1.2782\n",
      "Epoch 44/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6720 - mae: 1.2112 - val_loss: 5.1663 - val_mae: 1.2700\n",
      "Epoch 45/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6670 - mae: 1.2093 - val_loss: 5.1614 - val_mae: 1.2765\n",
      "Epoch 46/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6624 - mae: 1.2100 - val_loss: 5.1578 - val_mae: 1.2747\n",
      "Epoch 47/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6575 - mae: 1.2108 - val_loss: 5.1537 - val_mae: 1.2680\n",
      "Epoch 48/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6533 - mae: 1.2088 - val_loss: 5.1486 - val_mae: 1.2758\n",
      "Epoch 49/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6492 - mae: 1.2103 - val_loss: 5.1446 - val_mae: 1.2728\n",
      "Epoch 50/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6452 - mae: 1.2084 - val_loss: 5.1434 - val_mae: 1.2839\n",
      "Epoch 51/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6416 - mae: 1.2112 - val_loss: 5.1386 - val_mae: 1.2787\n",
      "Epoch 52/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6371 - mae: 1.2099 - val_loss: 5.1334 - val_mae: 1.2709\n",
      "Epoch 53/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6335 - mae: 1.2088 - val_loss: 5.1305 - val_mae: 1.2776\n",
      "Epoch 54/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6301 - mae: 1.2099 - val_loss: 5.1269 - val_mae: 1.2727\n",
      "Epoch 55/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6265 - mae: 1.2093 - val_loss: 5.1236 - val_mae: 1.2724\n",
      "Epoch 56/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6228 - mae: 1.2085 - val_loss: 5.1234 - val_mae: 1.2813\n",
      "Epoch 57/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6194 - mae: 1.2106 - val_loss: 5.1174 - val_mae: 1.2657\n",
      "Epoch 58/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6163 - mae: 1.2081 - val_loss: 5.1149 - val_mae: 1.2728\n",
      "Epoch 59/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.6131 - mae: 1.2096 - val_loss: 5.1121 - val_mae: 1.2708\n",
      "Epoch 60/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6099 - mae: 1.2079 - val_loss: 5.1083 - val_mae: 1.2724\n",
      "Epoch 61/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6064 - mae: 1.2078 - val_loss: 5.1091 - val_mae: 1.2804\n",
      "Epoch 62/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6043 - mae: 1.2087 - val_loss: 5.1034 - val_mae: 1.2736\n",
      "Epoch 63/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.6009 - mae: 1.2075 - val_loss: 5.1032 - val_mae: 1.2842\n",
      "Epoch 64/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5980 - mae: 1.2088 - val_loss: 5.0992 - val_mae: 1.2728\n",
      "Epoch 65/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5955 - mae: 1.2076 - val_loss: 5.0991 - val_mae: 1.2827\n",
      "Epoch 66/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5927 - mae: 1.2084 - val_loss: 5.0933 - val_mae: 1.2696\n",
      "Epoch 67/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5908 - mae: 1.2069 - val_loss: 5.0946 - val_mae: 1.2847\n",
      "Epoch 68/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5871 - mae: 1.2083 - val_loss: 5.0962 - val_mae: 1.2858\n",
      "Epoch 69/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5858 - mae: 1.2067 - val_loss: 5.0886 - val_mae: 1.2841\n",
      "Epoch 70/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5831 - mae: 1.2084 - val_loss: 5.0845 - val_mae: 1.2729\n",
      "Epoch 71/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5811 - mae: 1.2073 - val_loss: 5.0829 - val_mae: 1.2723\n",
      "Epoch 72/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5788 - mae: 1.2066 - val_loss: 5.0827 - val_mae: 1.2839\n",
      "Epoch 73/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5767 - mae: 1.2084 - val_loss: 5.0797 - val_mae: 1.2730\n",
      "Epoch 74/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5745 - mae: 1.2078 - val_loss: 5.0777 - val_mae: 1.2688\n",
      "Epoch 75/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5721 - mae: 1.2058 - val_loss: 5.0795 - val_mae: 1.2817\n",
      "Epoch 76/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5708 - mae: 1.2068 - val_loss: 5.0734 - val_mae: 1.2784\n",
      "Epoch 77/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5686 - mae: 1.2073 - val_loss: 5.0711 - val_mae: 1.2697\n",
      "Epoch 78/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5665 - mae: 1.2069 - val_loss: 5.0693 - val_mae: 1.2660\n",
      "Epoch 79/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5647 - mae: 1.2066 - val_loss: 5.0687 - val_mae: 1.2696\n",
      "Epoch 80/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5631 - mae: 1.2069 - val_loss: 5.0703 - val_mae: 1.2697\n",
      "Epoch 81/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5615 - mae: 1.2058 - val_loss: 5.0657 - val_mae: 1.2713\n",
      "Epoch 82/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5595 - mae: 1.2064 - val_loss: 5.0639 - val_mae: 1.2694\n",
      "Epoch 83/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5581 - mae: 1.2055 - val_loss: 5.0633 - val_mae: 1.2767\n",
      "Epoch 84/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5565 - mae: 1.2055 - val_loss: 5.0628 - val_mae: 1.2829\n",
      "Epoch 85/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5548 - mae: 1.2077 - val_loss: 5.0588 - val_mae: 1.2586\n",
      "Epoch 86/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5527 - mae: 1.2055 - val_loss: 5.0581 - val_mae: 1.2666\n",
      "Epoch 87/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5519 - mae: 1.2049 - val_loss: 5.0563 - val_mae: 1.2784\n",
      "Epoch 88/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5493 - mae: 1.2053 - val_loss: 5.0630 - val_mae: 1.2881\n",
      "Epoch 89/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5491 - mae: 1.2073 - val_loss: 5.0535 - val_mae: 1.2680\n",
      "Epoch 90/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5474 - mae: 1.2046 - val_loss: 5.0567 - val_mae: 1.2855\n",
      "Epoch 91/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5456 - mae: 1.2052 - val_loss: 5.0526 - val_mae: 1.2815\n",
      "Epoch 92/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5444 - mae: 1.2067 - val_loss: 5.0509 - val_mae: 1.2745\n",
      "Epoch 93/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5430 - mae: 1.2056 - val_loss: 5.0477 - val_mae: 1.2642\n",
      "Epoch 94/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5415 - mae: 1.2041 - val_loss: 5.0507 - val_mae: 1.2864\n",
      "Epoch 95/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5401 - mae: 1.2068 - val_loss: 5.0461 - val_mae: 1.2600\n",
      "Epoch 96/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5389 - mae: 1.2047 - val_loss: 5.0437 - val_mae: 1.2650\n",
      "Epoch 97/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5369 - mae: 1.2059 - val_loss: 5.0481 - val_mae: 1.2505\n",
      "Epoch 98/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5371 - mae: 1.2040 - val_loss: 5.0418 - val_mae: 1.2688\n",
      "Epoch 99/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5353 - mae: 1.2055 - val_loss: 5.0401 - val_mae: 1.2605\n",
      "Epoch 100/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5337 - mae: 1.2042 - val_loss: 5.0390 - val_mae: 1.2624\n",
      "Epoch 101/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5329 - mae: 1.2041 - val_loss: 5.0407 - val_mae: 1.2779\n",
      "Epoch 102/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5319 - mae: 1.2039 - val_loss: 5.0410 - val_mae: 1.2849\n",
      "Epoch 103/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5306 - mae: 1.2061 - val_loss: 5.0376 - val_mae: 1.2685\n",
      "Epoch 104/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5296 - mae: 1.2030 - val_loss: 5.0364 - val_mae: 1.2748\n",
      "Epoch 105/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5286 - mae: 1.2053 - val_loss: 5.0352 - val_mae: 1.2688\n",
      "Epoch 106/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5274 - mae: 1.2032 - val_loss: 5.0351 - val_mae: 1.2795\n",
      "Epoch 107/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5267 - mae: 1.2053 - val_loss: 5.0344 - val_mae: 1.2701\n",
      "Epoch 108/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5252 - mae: 1.2049 - val_loss: 5.0323 - val_mae: 1.2607\n",
      "Epoch 109/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5241 - mae: 1.2041 - val_loss: 5.0315 - val_mae: 1.2596\n",
      "Epoch 110/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5232 - mae: 1.2027 - val_loss: 5.0324 - val_mae: 1.2811\n",
      "Epoch 111/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5225 - mae: 1.2056 - val_loss: 5.0302 - val_mae: 1.2581\n",
      "Epoch 112/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5217 - mae: 1.2026 - val_loss: 5.0308 - val_mae: 1.2792\n",
      "Epoch 113/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5209 - mae: 1.2045 - val_loss: 5.0308 - val_mae: 1.2725\n",
      "Epoch 114/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5198 - mae: 1.2036 - val_loss: 5.0276 - val_mae: 1.2668\n",
      "Epoch 115/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5192 - mae: 1.2040 - val_loss: 5.0285 - val_mae: 1.2702\n",
      "Epoch 116/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5184 - mae: 1.2037 - val_loss: 5.0278 - val_mae: 1.2694\n",
      "Epoch 117/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5174 - mae: 1.2038 - val_loss: 5.0255 - val_mae: 1.2643\n",
      "Epoch 118/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5167 - mae: 1.2036 - val_loss: 5.0247 - val_mae: 1.2627\n",
      "Epoch 119/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5155 - mae: 1.2039 - val_loss: 5.0248 - val_mae: 1.2640\n",
      "Epoch 120/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5151 - mae: 1.2037 - val_loss: 5.0240 - val_mae: 1.2546\n",
      "Epoch 121/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5135 - mae: 1.2019 - val_loss: 5.0265 - val_mae: 1.2729\n",
      "Epoch 122/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5136 - mae: 1.2026 - val_loss: 5.0253 - val_mae: 1.2810\n",
      "Epoch 123/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5128 - mae: 1.2040 - val_loss: 5.0235 - val_mae: 1.2752\n",
      "Epoch 124/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5122 - mae: 1.2043 - val_loss: 5.0207 - val_mae: 1.2612s: 4.5047 - m\n",
      "Epoch 125/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5110 - mae: 1.2030 - val_loss: 5.0204 - val_mae: 1.2672\n",
      "Epoch 126/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5104 - mae: 1.2034 - val_loss: 5.0200 - val_mae: 1.2691\n",
      "Epoch 127/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5091 - mae: 1.2029 - val_loss: 5.0204 - val_mae: 1.2669\n",
      "Epoch 128/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5088 - mae: 1.2023 - val_loss: 5.0223 - val_mae: 1.2768\n",
      "Epoch 129/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5084 - mae: 1.2039 - val_loss: 5.0191 - val_mae: 1.2696\n",
      "Epoch 130/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5077 - mae: 1.2032 - val_loss: 5.0168 - val_mae: 1.2654\n",
      "Epoch 131/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.5068 - mae: 1.2026 - val_loss: 5.0169 - val_mae: 1.2676\n",
      "Epoch 132/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5063 - mae: 1.2032 - val_loss: 5.0158 - val_mae: 1.2674\n",
      "Epoch 133/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5055 - mae: 1.2019 - val_loss: 5.0180 - val_mae: 1.2814\n",
      "Epoch 134/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5053 - mae: 1.2025 - val_loss: 5.0166 - val_mae: 1.2777\n",
      "Epoch 135/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5045 - mae: 1.2041 - val_loss: 5.0141 - val_mae: 1.2619\n",
      "Epoch 136/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5039 - mae: 1.2017 - val_loss: 5.0135 - val_mae: 1.2672\n",
      "Epoch 137/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5027 - mae: 1.2040 - val_loss: 5.0146 - val_mae: 1.2530\n",
      "Epoch 138/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5027 - mae: 1.2024 - val_loss: 5.0122 - val_mae: 1.2605\n",
      "Epoch 139/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5022 - mae: 1.2024 - val_loss: 5.0123 - val_mae: 1.2619\n",
      "Epoch 140/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5013 - mae: 1.2023 - val_loss: 5.0114 - val_mae: 1.2674\n",
      "Epoch 141/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.5007 - mae: 1.2020 - val_loss: 5.0109 - val_mae: 1.2685\n",
      "Epoch 142/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4997 - mae: 1.2033 - val_loss: 5.0118 - val_mae: 1.2561\n",
      "Epoch 143/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4996 - mae: 1.2015 - val_loss: 5.0105 - val_mae: 1.2710\n",
      "Epoch 144/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4991 - mae: 1.2015 - val_loss: 5.0113 - val_mae: 1.2769\n",
      "Epoch 145/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4982 - mae: 1.2029 - val_loss: 5.0093 - val_mae: 1.2649\n",
      "Epoch 146/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4976 - mae: 1.2017 - val_loss: 5.0088 - val_mae: 1.2684\n",
      "Epoch 147/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4964 - mae: 1.2028 - val_loss: 5.0121 - val_mae: 1.2684\n",
      "Epoch 148/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4966 - mae: 1.2014 - val_loss: 5.0086 - val_mae: 1.2768\n",
      "Epoch 149/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4962 - mae: 1.2034 - val_loss: 5.0081 - val_mae: 1.2545\n",
      "Epoch 150/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4955 - mae: 1.2010 - val_loss: 5.0069 - val_mae: 1.2625\n",
      "Epoch 151/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4950 - mae: 1.2024 - val_loss: 5.0073 - val_mae: 1.2567\n",
      "Epoch 152/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4941 - mae: 1.2004 - val_loss: 5.0057 - val_mae: 1.2688\n",
      "Epoch 153/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4940 - mae: 1.2016 - val_loss: 5.0083 - val_mae: 1.2788\n",
      "Epoch 154/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4934 - mae: 1.2032 - val_loss: 5.0067 - val_mae: 1.25260s - loss: 4.5099 - m\n",
      "Epoch 155/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4926 - mae: 1.2010 - val_loss: 5.0061 - val_mae: 1.2658\n",
      "Epoch 156/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4921 - mae: 1.2014 - val_loss: 5.0048 - val_mae: 1.2747\n",
      "Epoch 157/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4916 - mae: 1.2022 - val_loss: 5.0084 - val_mae: 1.2748\n",
      "Epoch 158/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4913 - mae: 1.2027 - val_loss: 5.0043 - val_mae: 1.2570\n",
      "Epoch 159/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4907 - mae: 1.2006 - val_loss: 5.0048 - val_mae: 1.2654\n",
      "Epoch 160/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4901 - mae: 1.2015 - val_loss: 5.0034 - val_mae: 1.2599\n",
      "Epoch 161/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4894 - mae: 1.2006 - val_loss: 5.0026 - val_mae: 1.2669\n",
      "Epoch 162/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4891 - mae: 1.2010 - val_loss: 5.0032 - val_mae: 1.2673\n",
      "Epoch 163/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4889 - mae: 1.2013 - val_loss: 5.0027 - val_mae: 1.2602\n",
      "Epoch 164/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4877 - mae: 1.2011 - val_loss: 5.0022 - val_mae: 1.2639\n",
      "Epoch 165/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4875 - mae: 1.2011 - val_loss: 5.0020 - val_mae: 1.2646\n",
      "Epoch 166/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4871 - mae: 1.2019 - val_loss: 5.0005 - val_mae: 1.2526\n",
      "Epoch 167/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4866 - mae: 1.1992 - val_loss: 5.0053 - val_mae: 1.2772\n",
      "Epoch 168/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4859 - mae: 1.2021 - val_loss: 5.0011 - val_mae: 1.2563\n",
      "Epoch 169/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4857 - mae: 1.1999 - val_loss: 5.0041 - val_mae: 1.2751\n",
      "Epoch 170/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4831 - mae: 1.2005 - val_loss: 5.0000 - val_mae: 1.2683\n",
      "Epoch 171/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4847 - mae: 1.2003 - val_loss: 5.0034 - val_mae: 1.2721\n",
      "Epoch 172/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4846 - mae: 1.2011 - val_loss: 5.0064 - val_mae: 1.2794\n",
      "Epoch 173/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4844 - mae: 1.2009 - val_loss: 4.9991 - val_mae: 1.2696\n",
      "Epoch 174/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4834 - mae: 1.2005 - val_loss: 5.0009 - val_mae: 1.2739\n",
      "Epoch 175/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4833 - mae: 1.2008 - val_loss: 4.9979 - val_mae: 1.2591\n",
      "Epoch 176/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4823 - mae: 1.2008 - val_loss: 4.9984 - val_mae: 1.2661\n",
      "Epoch 177/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4821 - mae: 1.2009 - val_loss: 4.9998 - val_mae: 1.2714\n",
      "Epoch 178/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4817 - mae: 1.2004 - val_loss: 4.9977 - val_mae: 1.2667\n",
      "Epoch 179/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4805 - mae: 1.2007 - val_loss: 4.9992 - val_mae: 1.2597\n",
      "Epoch 180/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4812 - mae: 1.2002 - val_loss: 4.9973 - val_mae: 1.2629\n",
      "Epoch 181/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4799 - mae: 1.1999 - val_loss: 5.0027 - val_mae: 1.2838\n",
      "Epoch 182/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4810 - mae: 1.2013 - val_loss: 4.9962 - val_mae: 1.2587\n",
      "Epoch 183/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4800 - mae: 1.2002 - val_loss: 4.9959 - val_mae: 1.2672\n",
      "Epoch 184/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4794 - mae: 1.2000 - val_loss: 4.9967 - val_mae: 1.2631\n",
      "Epoch 185/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4779 - mae: 1.2003 - val_loss: 4.9945 - val_mae: 1.2633\n",
      "Epoch 186/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4789 - mae: 1.2008 - val_loss: 4.9968 - val_mae: 1.2629\n",
      "Epoch 187/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4787 - mae: 1.1998 - val_loss: 4.9937 - val_mae: 1.2608\n",
      "Epoch 188/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4776 - mae: 1.1990 - val_loss: 4.9978 - val_mae: 1.2799\n",
      "Epoch 189/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4772 - mae: 1.2005 - val_loss: 4.9950 - val_mae: 1.2602\n",
      "Epoch 190/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4774 - mae: 1.1993 - val_loss: 4.9936 - val_mae: 1.2633\n",
      "Epoch 191/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4770 - mae: 1.1998 - val_loss: 4.9945 - val_mae: 1.2621\n",
      "Epoch 192/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4759 - mae: 1.2004 - val_loss: 4.9942 - val_mae: 1.2552\n",
      "Epoch 193/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4763 - mae: 1.1987 - val_loss: 4.9938 - val_mae: 1.2709\n",
      "Epoch 194/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4755 - mae: 1.2000 - val_loss: 4.9929 - val_mae: 1.2681\n",
      "Epoch 195/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4747 - mae: 1.1998 - val_loss: 4.9934 - val_mae: 1.2567\n",
      "Epoch 196/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4752 - mae: 1.1994 - val_loss: 4.9926 - val_mae: 1.2620\n",
      "Epoch 197/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4746 - mae: 1.1987 - val_loss: 4.9989 - val_mae: 1.2821\n",
      "Epoch 198/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4743 - mae: 1.2010 - val_loss: 4.9924 - val_mae: 1.2557\n",
      "Epoch 199/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4739 - mae: 1.1981 - val_loss: 4.9924 - val_mae: 1.2630\n",
      "Epoch 200/400\n",
      "2276/2276 [==============================] - 2s 1ms/step - loss: 4.4737 - mae: 1.1997 - val_loss: 4.9912 - val_mae: 1.2608\n",
      "Epoch 201/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4730 - mae: 1.2003 - val_loss: 4.9919 - val_mae: 1.2468\n",
      "Epoch 202/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4732 - mae: 1.1987 - val_loss: 4.9913 - val_mae: 1.2663\n",
      "Epoch 203/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4727 - mae: 1.2000 - val_loss: 4.9909 - val_mae: 1.2564\n",
      "Epoch 204/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4722 - mae: 1.1999 - val_loss: 4.9925 - val_mae: 1.2471\n",
      "Epoch 205/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4718 - mae: 1.1981 - val_loss: 4.9922 - val_mae: 1.2591\n",
      "Epoch 206/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4716 - mae: 1.1985 - val_loss: 4.9961 - val_mae: 1.2726\n",
      "Epoch 207/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4708 - mae: 1.2004 - val_loss: 4.9903 - val_mae: 1.2679\n",
      "Epoch 208/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4717 - mae: 1.1985 - val_loss: 4.9915 - val_mae: 1.2722\n",
      "Epoch 209/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4706 - mae: 1.1987 - val_loss: 4.9905 - val_mae: 1.2738\n",
      "Epoch 210/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4703 - mae: 1.1996 - val_loss: 4.9901 - val_mae: 1.2630\n",
      "Epoch 211/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4698 - mae: 1.1994 - val_loss: 4.9894 - val_mae: 1.2598\n",
      "Epoch 212/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4697 - mae: 1.1988 - val_loss: 4.9894 - val_mae: 1.2595\n",
      "Epoch 213/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4700 - mae: 1.1989 - val_loss: 4.9895 - val_mae: 1.2636\n",
      "Epoch 214/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4695 - mae: 1.1988 - val_loss: 4.9928 - val_mae: 1.2770\n",
      "Epoch 215/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4691 - mae: 1.1993 - val_loss: 4.9883 - val_mae: 1.2599\n",
      "Epoch 216/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4689 - mae: 1.1981 - val_loss: 4.9895 - val_mae: 1.2780\n",
      "Epoch 217/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4684 - mae: 1.2006 - val_loss: 4.9887 - val_mae: 1.2627\n",
      "Epoch 218/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4681 - mae: 1.1995 - val_loss: 4.9920 - val_mae: 1.2391\n",
      "Epoch 219/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4680 - mae: 1.1984 - val_loss: 4.9898 - val_mae: 1.2497\n",
      "Epoch 220/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4679 - mae: 1.1987 - val_loss: 4.9876 - val_mae: 1.2586\n",
      "Epoch 221/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4668 - mae: 1.1976 - val_loss: 4.9961 - val_mae: 1.2846\n",
      "Epoch 222/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4677 - mae: 1.1989 - val_loss: 4.9893 - val_mae: 1.2794\n",
      "Epoch 223/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4673 - mae: 1.1990 - val_loss: 4.9898 - val_mae: 1.2767\n",
      "Epoch 224/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4669 - mae: 1.1996 - val_loss: 4.9883 - val_mae: 1.2647\n",
      "Epoch 225/400\n",
      "2276/2276 [==============================] - 3s 1ms/step - loss: 4.4669 - mae: 1.1983 - val_loss: 4.9876 - val_mae: 1.2704\n"
     ]
    }
   ],
   "source": [
    "model = init_model(27,learn = 0.00003)\n",
    "es = EarlyStopping(patience=5)\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train, \n",
    "                  batch_size=32, \n",
    "                  epochs=400, \n",
    "                  validation_split=0.3,\n",
    "                  callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ccbe87b",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 663us/step - loss: 4.1468 - mae: 1.0922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.146822929382324, 1.0921863317489624]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_eval = model.evaluate(X_test_scaled, y_test)\n",
    "y_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6086b697",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f82be0eb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from fflpred.baseline_model.baseline import mov_a_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a60d7c9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "baseline = mov_a_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6c1756",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "baseline.error.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7221156c",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Baseline 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bdfb81c0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "players_data = full_data[full_data['minutes'] > 0]\n",
    "\n",
    "data = roll_match_features(players_data, roll=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "645e5e98",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4023826599729063"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(data.r_total_points - data.real_total_points).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aa3e3ef0",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9770226722346167"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players_data.total_points.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
